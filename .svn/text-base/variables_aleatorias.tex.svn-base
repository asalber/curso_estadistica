%Version control information
%$HeadURL$} {$LastChangedDate$
%$LastChangedRevision$
%$LastChangedBy$

\section{Variables Aleatorias}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Variables aleatorias}
\tableofcontents[sectionstyle=show/hide,hideothersubsections]
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Variable aleatoria}
Cuando seleccionamos una muestra al azar de una población estamos realizando un experimento aleatorio y cualquier variable
estadística medida a partir de la muestra será una variable aleatoria porque sus valores dependerán del azar. 

\begin{definicion}[Variable Aleatoria] 
Una \emph{variable aleatoria} $X$ es una función que asocia un número real a cada elemento del
espacio muestral de un experimento aleatorio. \[ X:E\rightarrow \mathbb{R} \]

Al conjunto de posibles valores que puede tomar la variable aleatoria se le llama \emph{rango} o \emph{recorrido} de la variable.
\end{definicion}

En el fondo, una variable aleatoria es una variable cuyos valores provienen de la realización de un experimento aleatorio, y por tanto,
tendrá asociada una determinada distribución de probabilidad.

Un ejemplo de variable aleatoria es la que mide el resultado del lanzamiento de un dado.

\note{
Con este tema entramos de lleno en la inferencia estadística, que tiene por objeto construir modelos probabilísticos que
expliquen el comportamiento de las variables en las poblaciones. Estas variables se llaman variables aleatorias porque al medirlas en
la muestra obtenida al azar de la población, sus valores provienen de realizar un experimento aleatorio.  

\begin{definicion}[Variable Aleatoria] 
Una \emph{variable aleatoria} $X$ es una función que asocia un número real a cada elemento del
espacio muestral de un experimento aleatorio. \[ X:E\rightarrow \mathbb{R} \]

Al conjunto de posibles valores que puede tomar la variable aleatoria se le llama \emph{rango} o \emph{recorrido} de la variable.
\end{definicion}

Como los valores de una variable aleatoria provienen de la realización de un experimento aleatorio, 
tendrá asociada una determinada distribución de probabilidad. Nuestro objetivo es conocer lo mejor posible esa distribución de probabilidad
pero debemos recordar que cuando estudiemos una determinada variable,
normalmente no conoceremos con exactitud cómo se distribuyen sus valores en la población, ya que no podremos medir a todos los invididuos de
la misma. Por tanto, los modelos de distribución de probabilidad que utilizaremos para describir el comportamiento de las variables en las
poblaciones serán modelos aproximados. 

Un ejemplo de variable aleatoria es la que mide el resultado del lanzamiento de un dado.
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Variable aleatoria}
Las variables aleatorias se clasifican en dos tipos:
\begin{description}
\item[Discretas (VAD):] Toman valores aislados (recorrido finito o infinito numerable).\\
Ejemplo. Número de hijos, número de accidentes, número de cigarrillos, etc. 
\item[Continuas (VAC):] Toman valores en un intervalo real.\\
Ejemplo. Peso, estatura, nivel de colesterol, tiempo de respuesta a un fármaco, etc. 
\end{description}

Los modelos probabilísticos de cada tipo de variables tienen características diferenciadas y por eso se estudiarán por separado. 

\note{
Las variables aleatorias se clasifican en dos tipos:
\begin{description}
\item[Discretas (VAD):] Toman valores aislados (recorrido finito o infinito numerable).\\
Ejemplo. Número de hijos, número de accidentes, número de cigarrillos, etc. 
\item[Continuas (VAC):] Toman valores en un intervalo real.\\
Ejemplo. Peso, estatura, nivel de colesterol, tiempo de respuesta a un fármaco, etc. 
\end{description}

Los modelos probabilísticos de cada tipo de variables tienen características diferenciadas y por eso se estudiarán por separado. 
}
\end{frame}


\subsection{Variables Aleatorias Discretas}

%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Distribución de probabilidad de una variable discreta}
Como los valores de una variable aleatoria están asociados a los sucesos elementales del correspondiente experimento aleatorio, cada valor
tendrá asociada una probabilidad.
\begin{definicion}[Función de probabilidad]
La \emph{función de probabilidad} de una variable aleatoria discreta $X$ es una función $f(x)$ que asocia a cada valor su probabilidad
\[
f(x_i) = P(X=x_i).
\] 
\end{definicion} 

Las probabilidades también pueden acumularse, al igual que se acumulaban las frecuencias en las muestras.

\begin{definicion}[Función de distibución] 
La \emph{función de distribución} de una variable aleatoria discreta $X$ es una función $F(x)$
que asocia a cada valor $x_i$ la probabilidad de que la variable tome un valor menor o igual que dicho valor. 
\[
F(x_i) = P(X\leq x_i) = f(x_1)+\cdots +f(x_i).
\]
\end{definicion} 

\note{
Como los valores de una variable aleatoria están asociados a los sucesos elementales del correspondiente experimento aleatorio, cada valor
tendrá asociada una probabilidad.
\begin{definicion}[Función de probabilidad]
La \emph{función de probabilidad} de una variable aleatoria discreta $X$ es una función $f(x)$ que asocia a cada valor su probabilidad
\[
f(x_i) = P(X=x_i).
\] 
\end{definicion}  

Al igual que se acumulaban las frecuencias en las muestras, tiene sentido acumular probabilidades en las poblaciones. De eso se encarga la
función de distribución.

\begin{definicion}[Función de distibución] 
La \emph{función de distribución} de una variable aleatoria discreta $X$ es una función $F(x)$
que asocia a cada valor $x_i$ la probabilidad de que la variable tome un valor menor o igual que dicho valor. 
\[
F(x_i) = P(X\leq x_i) = f(x_1)+\cdots +f(x_i).
\]
\end{definicion} 
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Distribución de probabilidad de una variable discreta}
Al recorrido de la variable, junto a su función de probabilidad o de distribución, se le llama \structure{\textbf{Distribución de probabilidad}} de la variable.

Tanto la función de probabilidad como la de distribución suelen representarse en forma de tabla
\[
\begin{array}{|c|cccc|c|}
\hline
X & x_1 & x_2 & \cdots & x_n & \sum\\ \hline
f(x) & f(x_1) & f(x_2) & \cdots & f(x_n) & 1\\
\hline
F(x) & F(x_1) & F(x_2) & \cdots & F(x_n) =1 &\multicolumn{1}{|c}{} \\
\cline{1-5}
\end{array}
\]

Al igual que la distribución de frecuencias de una variable reflejaba cómo se distribuían los valores de la variable en una muestra, la
distribución de probabilidad de una variable aleatoria sirve para reflejar cómo se distribuyen los valores de dicha variable en toda la
población.

\note{
Al recorrido de la variable, junto a su función de probabilidad o de distribución, se le llama \structure{\textbf{Distribución de probabilidad}} de la variable.

Tanto la función de probabilidad como la de distribución suelen representarse en forma de tabla
\[
\begin{array}{|c|cccc|c|}
\hline
X & x_1 & x_2 & \cdots & x_n & \sum\\ \hline
f(x) & f(x_1) & f(x_2) & \cdots & f(x_n) & 1\\
\hline
F(x) & F(x_1) & F(x_2) & \cdots & F(x_n) =1 &\multicolumn{1}{|c}{} \\
\cline{1-5}
\end{array}
\]

Al igual que la distribución de frecuencias de una variable reflejaba cómo se distribuían los valores de la variable en una muestra, la
distribución de probabilidad de una variable aleatoria sirve para reflejar cómo se distribuyen los valores de dicha variable en toda la
población.
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Distribución de probabilidad de una variable discreta}
\framesubtitle{Ejemplo del lanzamiento de dos monedas}
Sea $X$ la variable aleatoria que mide el número de caras en el lanzamiento de dos monedas. 


El árbol de probabilidad asociado al experimento es 
\begin{center}
\scalebox{0.8}{
\psset{treesep=0.5cm, levelsep=2.5cm, tpos=0.7}
\renewcommand{\psedge}[2]{\ncdiag[armA=0.8cm,angleA=180,angleB=0,armB=0cm]{#2}{#1}} 
\pstree[treemode=R, nodesep=1pt]{\Tp*}{
	\pstree[linestyle=none]{\TR[edge=none]{1ª Moneda}}{
		\pstree[levelsep=2cm]{\TR{2ª Moneda}}{
			\pstree{\TR{$E$}}{
				\pstree{\TR{$P$}}{\TR{$X$}}
			}
		}
	}
	\pstree{\TR{C}\taput{\scriptsize $0.5$}}{
		\pstree[linestyle=none,levelsep=2cm]{\TR{C}\taput{\scriptsize $0.5$}}{
			\pstree{\TR{(C,C)}}{
				\pstree{\TR{$0.25$}}{\TR{$2$}}
			}
		}
		\pstree[linestyle=none,levelsep=2cm]{\TR{X}\taput{\scriptsize $0.5$}}{
			\pstree{\TR{(C,X)}}{
				\pstree{\TR{$0.25$}}{\TR{$1$}}
			}
		}
	}
	\pstree{\TR{X}\taput{\scriptsize $0.5$}}{
		\pstree[linestyle=none,levelsep=2cm]{\TR{C}\taput{\scriptsize $0.5$}}{
			\pstree{\TR{(X,C)}}{
				\pstree{\TR{$0.25$}}{\TR{$1$}}
			}
		}
		\pstree[linestyle=none,levelsep=2cm]{\TR{X}\taput{\scriptsize $0.5$}}{
			\pstree{\TR{(X,X)}}{
				\pstree{\TR{$0.25$}}{\TR{$0$}}
			}
		}
	}
	\pstree[linestyle=none]{\Tp[edge=none]}{\Tp}
}
}
\end{center}
y según esto, su distribución de probabilidad es
\[
\begin{array}{|c|ccc|}
\hline
X & 0 & 1 & 2\\ \hline
f(x) & 0.25 & 0.5 & 0.25\\
\hline
F(x) & 0.25 & 0.75 & 1 \\
\hline 
\end{array}
\qquad
F(x) =
\begin{cases}
0 & \mbox{si $x<0$}\\
0.25 & \mbox{si $0\leq x< 1$}\\
0.75 & \mbox{si $1\leq x< 2$}\\
1 & \mbox{si $x\geq 2$}
\end{cases}
\]
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Gráficos de la funciones de probabilidad y distribución}
\framesubtitle{Ejemplo del lanzamiento de dos monedas}
\begin{center}
\begin{tabular}{cc}
Función de probabilidad & Función de distribución\\
\scalebox{0.5}{\input{img/variables_aleatorias_discretas/funcion_probabilidad_lanzamiento_2_monedas}}
&
\scalebox{0.5}{\input{img/variables_aleatorias_discretas/funcion_distribucion_lanzamiento_2_monedas}}
\end{tabular}
\end{center}

\note{
Tanto la función de probabilidad como la de distribución también suelen representarse gráficamente, de igual modo que representabamos las
frecuencias muestrales.

Como se trata de variables discretas, el diagrama que se utiliza es el diagrama de barras o el diagrama de puntos, donde para cada valor se
levanta una barra con el valor de la función de probabilidad o con el valor de la función de distribución.

En el ejemplo de la variable que mide el número de caras al lanzar dos monedas, se tiene que la gráfica de la función de probabilidad es
la que aparece a la izquierda, mientras que la de la función de distribución es la de la derecha.
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Estadísticos poblacionales}
Al igual que para describir las variables medidas en las muestras se utilizan estadísticos descriptivos, para describir determinadas
características de las variables aleatorias se utilizan también estadísticos poblacionales.

La definición de los estadísticos poblacionales es análoga a la de los muestrales, pero utilizando probabilidades en lugar de frecuencias
relativas.

Los más importantes son\footnote{Para distinguirlos de los muestrales se suelen representar con letras griegas}:
\begin{itemize}
\item \structure{Media o esperanza matemática}:
\[
\mu = E(X) = \sum_{i=1}^n x_i f(x_i)
\]
\item \structure{Varianza}:
\[
\sigma^2 = Var(X) = \sum_{i=1}^n x_i^2 f(x_i) -\mu^2
\]
\item \structure{Desviación típica}:
\[
\sigma = +\sqrt{\sigma^2}
\] 
\end{itemize}

\note{
Al igual que para describir las variables medidas en las muestras se utilizan estadísticos descriptivos, para describir determinadas
características de variables aleatorias se utilizan también estadísticos poblacionales.

Los estadísticos poblacionales se representan con letras griegas para distinguirlos de los muestrales, y su definición es análoga a la de
los muestrales, pero utilizando probabilidades en lugar de frecuencias relativas.

Por ejemplo, si definíamos la media muestral como la suma del producto de cada valor por su frecuencia relativa, la media poblacional, que
también se llama esperanza matemática, y se representa por $\mu$, se calcula como la suma del producto de cada valor de la variable por su
probabilidad. 

La varianza poblacional se calcula sumando los productos de los cuadrados de los valores de la variable por su probabilidad y restandole al
total de la suma la media poblacional al cuadrado. 

La desviación típica poblacional, como siempre, es la raíz cuadrada positiva de la varianza poblacional.

Otros estadísticos, se definen de forma similar a como lo hacíamos para muestras. Por ejemplo, la mediana será el valor cuya probabilidad
acumulada sea $0.5$. 
}

\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Estadísticos poblacionales}
\framesubtitle{Ejemplo de cálculo en el caso del lanzamiento de dos monedas}
En el ejemplo del lanzamiento de dos monedas, a partir de la distribución de probabilidad
\[
\begin{array}{|c|ccc|}
\hline
X & 0 & 1 & 2\\ \hline
f(x) & 0.25 & 0.5 & 0.25\\
\hline
F(x) & 0.25 & 0.75 & 1 \\
\hline 
\end{array}
\]
se pueden calcular fácilmente los estadísticos poblacionales:
\begin{align*}
\mu &= \sum_{i=1}^n x_i f(x_i) = 0\cdot 0.25 + 1\cdot 0.5 + 2\cdot 0.25 = 1 \mbox{ cara},\\
\sigma^2 &= \sum_{i=1}^n x_i^2 f(x_i) -\mu^2 = (0^0\cdot 0.25 + 1^2\cdot 0.5 + 2^2\cdot 0.25) - 1^2 = 0.5 \mbox{ caras}^2,\\
\sigma &= +\sqrt{0.5} = 0.71 \mbox{ caras}.
\end{align*} 

\note{
Veamos cómo calcular los principales estadísticos de la variable que medía el número de caras en el lanzamiento de dos monedas. 
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Modelos de distribución de probabilidad}
En teoría, para obtener la distribución de probabilidad de una variable aleatoria en una población es necesario conocer el valor de la
variable en todos los individuos de la población, lo cual muchas veces es imposible.

Sin embargo, dependiendo de la naturaleza del experimento, a veces es posible obtener la distribución de probabilidad de una variable
aleatoria sin medirla en toda la población.

Dependiendo del tipo de experimento, existen diferentes modelos de distribución de probabilidad discretos. Los más habituales son:
\begin{itemize}
\item Distribución Uniforme.
\item Distribución Binomial.
\item Distribución de Poisson.
\end{itemize}

\note{
En teoría, para obtener la distribución de probabilidad de una variable aleatoria en una población es necesario conocer el valor de la
variable en todos los individuos de la población, lo cual muchas es imposible la mayoría de las veces.

Sin embargo, dependiendo de la naturaleza del experimento, a veces es posible obtener la distribución de probabilidad de una variable
aleatoria sin medirla en toda la población.

Dependiendo del tipo de experimento, existen diferentes modelos de distribución de probabilidad discretos. Los más habituales son:
\begin{itemize}
\item Distribución Uniforme.
\item Distribución Binomial.
\item Distribución de Poisson.
\end{itemize}

A continuación los veremos uno por uno.
}
\end{frame}


\subsection{Distribución Uniforme}

% ---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Distribución Uniforme $U_d(a,b)$}
Cuando por la simetría del experimento, todos los valores $a=x_1,\ldots,x_k=b$ de una variable discreta $X$ son igualmente probables, se
dice que la variable sigue un \emph{modelo de distribución uniforme}.

\begin{definicion}[Distribución uniforme $U_d(a,b)$]
Se dice que una variable aleatoria $X$ sigue un \emph{modelo de distribución uniforme} de parámetros $a,b$, y se nota,
$X\sim U_d(a,b)$, si su recorrido es $Re(X) = \{a=x_1,\ldots,x_k=b\}$, y su función de probabilidad vale
\[f(x_i)=\frac{1}{k}.\]
\end{definicion}

Su media y varianza valen
\[
\mu = \sum_{i=1}^{k}x_i\frac{1}{k} \qquad \sigma^2 =\sum_{i=1}^k (x_i-\mu)^2\frac{1}{k}.
\]

\note{
Cuando por la simetría del experimento, todos los valores $a=x_1,\ldots,x_k=b$ de una variable discreta $X$ son igualmente probables, se
dice que la variable sigue un \emph{modelo de distribución uniforme}.

\begin{definicion}[Distribución uniforme $U_d(a,b)$]
Se dice que una variable aleatoria $X$ sigue un \emph{modelo de distribución uniforme} de parámetros $a,b$, y se nota,
$X\sim U_d(a,b)$, si puede tomar $k$ valores distintos desde $a$ hasta $b$, es decir, su recorrido es $Re(X) = \{a=x_1,\ldots,x_k=b\}$, y su
función de probabilidad de cada uno de estos valores es la misma, es decir,  \[f(x_i)=\frac{1}{k}.\]
\end{definicion}

Su media, valdrá, por tanto, 
\[
\mu = \sum_{i=1}^{k}x_i\frac{1}{k}.
\]
y su varianza
\[
\sigma^2 =\sum_{i=1}^k (x_i-\mu)^2\frac{1}{k}.
\]
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Distribución Uniforme $U_d(a,b)$}
\framesubtitle{Ejemplo del lanzamiento de un dado}
En el lanzamiento de un dado la variable que mide el número obtenido sigue un modelo de distribución uniforme
$U_d(1,6)$.
\begin{center}
\scalebox{0.65}{\input{img/variables_aleatorias_discretas/funcion_probabilidad_uniforme}}
\end{center}

\note{
Un ejemplo sencillo de variable con distribución uniforme es la que mide el resultado del lanzamiento de un dado. Como puede tomar 6 valores
distintos del 1 al 6, su función de probabilidad es constante vale $1/6$ para cualquier valor, tal y como se aprecia en la gráfica.

El modelo de distribución uniforme es el más sencillo, pero resulta poco útil en la práctica ya que la equiprobabilidad no suele cumplirse
fuera de los juegos de azar.
}
\end{frame}


\subsection{Distribución Binomial}

%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Distribución Binomial}
Sea un experimento aleatorio con las siguientes características:
\begin{itemize}
\item El experimento consiste en una secuencia de $n$ repeticiones de un mismo ensayo aleatorio.
\item Los ensayos se realizan bajo idénticas condiciones, y cada uno de ellos tiene únicamente dos posibles resultados,
que habitualmente se denotan por éxito ($A$) o fracaso ($\overline A$).
\item Los ensayos son independientes, por lo que el resultado de cualquier ensayo en particular no influye sobre el resultado de cualquier otro.
\item La probabilidad de éxito es idéntica para todos los ensayos y vale $P(A)=p$.
\end{itemize}
En estas condiciones, la variable aleatoria $X$ que mide le número de éxitos obtenidos en los $n$ ensayos sigue un
\emph{modelo de distribución binomial} de parámetros $n$ y $p$.

\note{
Mucho más habitual es el modelo binomial, que suele darse en experimentos aleatorios con las siguientes características:
\begin{itemize}
\item El experimento consiste en una secuencia de $n$ repeticiones de un mismo ensayo aleatorio. Por ejemplo, tirar 10 veces una moneda. 
\item Los ensayos se realizan bajo idénticas condiciones, y cada uno de ellos tiene únicamente dos posibles resultados,
que habitualmente se denotan por éxito ($A$) o fracaso ($\overline A$). Por ejemplo, medir en cada lanzamiento si sale cara (éxito) o si
sale cruz (fracaso).
\item Los ensayos son independientes, por lo que el resultado de cualquier ensayo en particular no influye sobre el resultado de cualquier
otro. Por ejemplo, el resultado de cada lanzamiento de la moneda no depende de los otros.
\item La probabilidad de éxito es idéntica para todos los ensayos y vale $P(A)=p$. Por ejemplo, la probabilidad de sacar cara es $0.5$ en
todos los lanzamientos. 
\end{itemize}
En estas condiciones, la variable aleatoria $X$ que mide le número de éxitos obtenidos en los $n$ ensayos sigue un
\emph{modelo de distribución binomial} de parámetros $n$ y $p$, donde $n$ era el número de repeticiones del ensayo y $p$ es la probabilidad
de lo que llamemos éxito. Así, la variable que mide el número de caras obtenidas en 10 lanzamientos de una moneda es sigue un modelo de
distribución binomial de parámetros $n=10$ y $p=0.5$.

}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Distribución Binomial $B(n,p)$}
\begin{definicion}[Distribución Binomial $(B(n,p)$]
Se dice que una variable aleatoria $X$ sigue un \emph{modelo de distribución binomial} de parámetros $n$ y $p$, si su recorrido es $Re(X) =
\{0,1,...,n\}$, y su función de probabilidad vale
\[
f(x) = \binom{n}{x}p^x(1-p)^{n-x} = \frac{n!}{x!(n-x)!}p^x(1-p)^{n-x}.
\]
\end{definicion}

Su media y varianza valen
\[
\mu = n\cdot p \qquad \sigma^2 = n\cdot p\cdot (1-p).
\]

\note{
Una variable con distribución binomial cumple que su recorrido va de $0$ a $n$ y su función de probablidad viene dada por la fórmula
\[
f(x) = \binom{n}{x}p^x(1-p)^{n-x}.
\]
donde el número combinatorio $\binom{n}{x}$ se define como $\frac{n!}{x!(n-x)!}$ y $n!$ es el producto de todos los números consecutivos
desde $1$ hasta $n$.

Se cumple además que su media es 
\[
\mu = n\cdot p.
\]
y su varianza
\[
\sigma^2 = n\cdot p\cdot (1-p).
\]
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Distribución Binomial $B(n,p)$}
\framesubtitle{Ejemplo de 10 lanzamientos de una moneda}
La variable que mide el número de caras obtenidos al lanzar 10 veces una moneda sigue un modelo de distribución binomial $B(10,\,0.5)$.
\begin{center}
\scalebox{0.65}{\input{img/variables_aleatorias_discretas/funcion_probabilidad_binomial}}
\end{center}

\note{
Ya hemos visto que la variable que mide el número de caras obtenidos al lanzar 10 veces una moneda sigue un modelo de distribución binomial
$B(10,\,0.5)$. 

La gráfica de su función de probabilidad es esta. En ella se puede observar como se reparte la probabilidad entre los distintos valores que
van de 0 a 10. Obsérvese como el 0 y el 10 tienen probabilidades muy bajas, ya que es muy difícil que al tirar diez veces una moneda no se
obtenga ninguna cara, lo mismo que obtener 10 caras. Lo más probable, como se aprecia en el gráfico, es sacar 5 caras, que además es su
media.
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Distribución Binomial $B(n,p)$}
\framesubtitle{Ejemplo de 10 lanzamientos de una monedas}
Sea $X\sim B(10,\,0.5)$ la variable que mide el número de caras en 10 lanzamientos de una moneda. Entonces:
\begin{itemize}
\item La probabilidad de sacar 4 caras es
\[
f(4) = \binom{10}{4}0.5^4 (1-0.5)^{10-4} = \frac{10!}{4!6!}0.5^40.5^6 = 210\cdot 0.5^{10} = 0.2051.
\]
\item La probabilidad de sacar dos o menos caras es
\begin{align*}
F(2) &= f(0) +f(1) + f(2) =\\
&= \binom{10}{0}0.5^0 (1-0.5)^{10-0} + \binom{10}{1}0.5^1 (1-0.5)^{10-1} + \binom{10}{2}0.5^2 (1-0.5)^{10-2} =\\
&= 0.0547.
\end{align*}
\item Y el número esperado de caras es 
\[ \mu = 10\cdot 0.5 = 5 \mbox{ caras}.\]   
\end{itemize}

\note{
Conocer la fórmula de la función de probabilidad de la binomial facilita mucho el cálculo de probabilidades para esta variable. Por ejemplo,
\begin{itemize}
\item La probabilidad de sacar 4 caras es
\[
f(4) = \binom{10}{4}0.5^4 (1-0.5)^{10-4} = \frac{10!}{4!6!}0.5^40.5^6 = 210\cdot 0.5^{10} = 0.2051.
\]
\item La probabilidad de sacar dos o menos caras es
\begin{align*}
F(2) &= f(0) +f(1) + f(2) =\\
&= \binom{10}{0}0.5^0 (1-0.5)^{10-0} + \binom{10}{1}0.5^1 (1-0.5)^{10-1} + \binom{10}{2}0.5^2 (1-0.5)^{10-2} =\\
&= 0.0547.
\end{align*}
\item Y el número esperado de caras, es decir, la media es 
\[ \mu = 10\cdot 0.5 = 5 \mbox{ caras}.\]   
\end{itemize}
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Distribución Binomial $B(n,p)$}
\framesubtitle{Ejemplo de una muestra aleatoria con reemplazamiento}
Dada una población con un 40\% de hombres y un 60\% de mujeres, la variable que mide el número de mujeres en una muestra
aleatoria de tamaño 3, sigue una distribución binomial $X\sim B(3,\,0.6)$.

\begin{center}
\scalebox{0.7}{
\psset{treesep=0.4cm, levelsep=2cm, tpos=0.7}
\renewcommand{\psedge}[2]{\ncdiag[armA=0.8cm,angleA=180,angleB=0,armB=0cm]{#2}{#1}} 
\pstree[treemode=R, nodesep=1pt]{\Tp*}{
	\pstree[linestyle=none]{\TR[edge=none]{1ª Persona}}{
		\pstree{\TR{2ª Persona}}{
			\pstree[thislevelsep=1.5cm]{\TR{3ª Persona}}{
				\pstree[thislevelsep=1.5cm]{\TR{$E$}}{
					\pstree[thislevelsep=1.5cm]{\TR{$X$}}{\TR{$P$}}
				}
			}
		}
	}
	\pstree{\TR{H}\taput{\scriptsize $0.4$}}{
		\pstree{\TR{H}\taput{\scriptsize $0.4$}}{
			\pstree[linestyle=none,thislevelsep=1.5cm]{\TR{H}\taput{\scriptsize $0.4$}}{
				\pstree[thislevelsep=1.5cm]{\TR{(H,H,H)}}{
					\pstree[thislevelsep=1.5cm]{\TR{\uncover<2->{0}}}{\TR{$0.4^3$}}
				}
			}
			\pstree[linestyle=none,thislevelsep=1.5cm]{\TR{M}\taput{\scriptsize $0.6$}}{
				\pstree[thislevelsep=1.5cm]{\TR{(H,H,M)}}{
					\pstree[thislevelsep=1.5cm]{\TR{\uncover<3->{1}}}{\TR{$0.6\cdot0.4^2$}}
				}
			}
		}
		\pstree{\TR{M}\taput{\scriptsize $0.6$}}{
			\pstree[linestyle=none,thislevelsep=1.5cm]{\TR{H}\taput{\scriptsize $0.4$}}{
				\pstree[thislevelsep=1.5cm]{\TR{(H,M,H)}}{
					\pstree[thislevelsep=1.5cm]{\TR{\uncover<3->{1}}}{\TR{$0.6\cdot 0.4^2$}}
				}
			}
			\pstree[linestyle=none,thislevelsep=1.5cm]{\TR{M}\taput{\scriptsize $0.6$}}{
				\pstree[thislevelsep=1.5cm]{\TR{(H,M,M)}}{
					\pstree[thislevelsep=1.5cm]{\TR{\uncover<4->{2}}}{\TR{$0.6^2\cdot 0.4$}}
				}
			}
		}	
	}
	\pstree{\TR{M}\taput{\scriptsize $0.6$}}{
		\pstree{\TR{H}\taput{\scriptsize $0.4$}}{
			\pstree[linestyle=none,thislevelsep=1.5cm]{\TR{H}\taput{\scriptsize $0.4$}}{
				\pstree[thislevelsep=1.5cm]{\TR{(M,H,H)}}{
					\pstree[thislevelsep=1.5cm]{\TR{\uncover<3->{1}}}{\TR{$0.6\cdot 0.4^2$}}
				}
			}
			\pstree[linestyle=none,thislevelsep=1.5cm]{\TR{M}\taput{\scriptsize $0.6$}}{
				\pstree[thislevelsep=1.5cm]{\TR{(M,H,M)}}{
					\pstree[thislevelsep=1.5cm]{\TR{\uncover<4->{2}}}{\TR{$0.6^2\cdot 0.4$}}
				}
			}
		}
		\pstree{\TR{M}\taput{\scriptsize $0.6$}}{
			\pstree[linestyle=none,thislevelsep=1.5cm]{\TR{H}\taput{\scriptsize $0.4$}}{
				\pstree[thislevelsep=1.5cm]{\TR{(M,M,H)}}{
					\pstree[thislevelsep=1.5cm]{\TR{\uncover<4->{2}}}{\TR{$0.6^2\cdot 0.4$}}
				}
			}
			\pstree[linestyle=none,thislevelsep=1.5cm]{\TR{M}\taput{\scriptsize $0.6$}}{
				\pstree[thislevelsep=1.5cm]{\TR{(M,M,M)}}{
					\pstree[thislevelsep=1.5cm]{\TR{\uncover<5->{3}}}{\TR{$0.6^3$}}
				}
			}
		}	
	}
	\pstree[linestyle=none]{\Tp[edge=none]}{\Tp}
}
}
\end{center}

\scalebox{0.9}{
\[
\renewcommand{\arraystretch}{1.5}
\begin{array}{lll}
\uncover<2->{f(0)=\binom{3}{0}0.6^0(1-0.6)^{3-0}= 0.4^3,} & \quad & 
\uncover<3->{f(1)=\binom{3}{1}0.6^1(1-0.6)^{3-1}= 3\cdot 0.6\cdot 0.4^2,}\\
\uncover<4->{f(2)=\binom{3}{2}0.6^2(1-0.6)^{3-2}= 3\cdot 0.6^2\cdot 0.4,} & & 
\uncover<5->{f(3)=\binom{3}{3}0.6^3(1-0.6)^{3-3}= 0.6^3.}
\end{array}
\]
}
\end{frame}


\subsection{Distribución de Poisson}

% ---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Distribución de Poisson}
Sea un experimento aleatorio con las siguientes características:
\begin{itemize}
\item El experimento consiste en observar la aparición de fenómenos puntuales sobre un soporte continuo, ya sea espacial o temporal. Por
ejemplo: averías de máquinas en un espacio de tiempo, recepción de llamadas en una centralita, nº de linfocitos en un volumen de
sangre,etc.
\item El experimento produce, a largo plazo, un número medio constante de fenómenos puntuales por unidad de soporte continuo que llamaremos
$\lambda$.
\end{itemize}
En estas circunstancias, la variable aleatoria $X$ que mide el número de ocurrencias del fenómeno por unidad de soporte
continuo sigue un \emph{modelo de distribución de Poisson} de parámetro $\lambda$.

\note{
La distribución de Poisson surge en experimentos aleatorios con las siguientes características:
\begin{itemize}
\item El experimento consiste en observar la aparición de fenómenos puntuales sobre un soporte continuo, ya sea espacial o temporal. Por
ejemplo: averías de máquinas en un espacio de tiempo, recepción de llamadas en una centralita, nº de linfocitos en un volumen de
sangre,etc.
\item Además el experimento produce, a largo plazo, un número medio constante de fenómenos puntuales por unidad de soporte continuo que
llamaremos $\lambda$.
\end{itemize}
En estas circunstancias, la variable aleatoria $X$ que mide el número de ocurrencias del fenómeno por unidad de soporte
continuo sigue un \emph{modelo de distribución de Poisson} de parámetro $\lambda$.
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Distribución de Poisson $P(\lambda)$}
\begin{definicion}[Distribución de Poisson $P(\lambda)$]
Se dice que una variable aleatoria $X$ sigue un \emph{modelo de distribución de Poisson} de parámetro $\lambda$ si su recorrido es $Re(X) = \{0,1,...,\infty\}$, y su función de probabilidad vale
\[
f(x) = e^{-\lambda}\frac{\lambda^x}{x!}.
\]
\end{definicion}

Su media y varianza valen
\[
\mu = \lambda \qquad \sigma^2 = \lambda.
\]

\note{
Una variable aleatoria con distribución de Poisson de parámetro $\lambda$ puede tomar valores de $0$ a $\infty$, y
su función de probabilidad viende dada por la fórmula
\[
f(x) = e^{-\lambda}\frac{\lambda^x}{x!}.
\]

Además, tanto su media como su varianza valen $\lambda$.
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Distribución de Poisson $P(\lambda)$}
\framesubtitle{Ejemplo del número de ingresos en un hospital}
Sea un hospital en el que se producen por término medio 4 ingresos diarios. Entonces la variable aleatoria $X$ que mide el número de
ingresos en un día sigue un modelo de distribución de Poisson $X\sim P(4)$.
\begin{center}
\scalebox{0.63}{\input{img/variables_aleatorias_discretas/funcion_probabilidad_poisson}}
\end{center}

\note{
Sea un hospital en el que se producen por término medio 4 ingresos diarios. Entonces la variable aleatoria $X$ que mide el número de
ingresos en un día sigue un modelo de distribución de Poisson $X\sim P(4)$, y la gráfica de la función de probabilidad es esta. Obsérvese
cómo, aunque teóricamente la variable podría tomar valores hasta $\infty$, la probabilidad de que ocurran más de 10 ingresos ya es casi
despreciable. 
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Distribución de Poisson $P(\lambda)$}
\framesubtitle{Ejemplo del número de ingresos en un hospital}
Sea $X\sim P(4)$ la variable que mide el número de ingresos diarios en un hospital. Entonces:
\begin{itemize}
\item La probabilidad de que un día cualquiera se produzcan 5 ingresos es
\[
f(5) = e^{-4}\frac{4^5}{5!} = 0.1563.
\]
\item La probabilidad de que un día se produzcan menos de 2 ingresos es
\[
F(1) = f(0)+f(1) = e^{-4}\frac{4^0}{0!} + e^{-4}\frac{4^1}{1!} = 5e^{-4} = 0.0916.
\]
\item La probabilidad de que un día se produzcan más de un 1 ingresos es
\[
P(X> 1) = 1- P(X\leq 1) = 1- F(1) = 1- 0.0916 = 0.9084.
\]
\end{itemize}

\note{
Ya hemos visto que la variable que mide el número de ingresos diarios en un hospital donde por término medio se producen 4 ingresos al día,
sigue un modelo de distribución de Poisson $P(4)$. Entonces:
\begin{itemize}
\item La probabilidad de que un día cualquiera se produzcan 5 ingresos es
\[
f(5) = e^{-4}\frac{4^5}{5!} = 0.1563.
\]
\item La probabilidad de que un día se produzcan menos de 2 ingresos es
\[
F(1) = f(0)+f(1) = e^{-4}\frac{4^0}{0!} + e^{-4}\frac{4^1}{1!} = 5e^{-4} = 0.0916.
\]
\item La probabilidad de que un día se produzcan más de un 1 ingresos es
\[
P(X> 1).
\]
Pero esta probabilidad es $f(1)+f(2)+\cdots$, hasta infinito, de modo que para calcularla tenemos que recurrir a la probabilidad del suceso
contrario, es decir,
\[
P(X> 1) = 1- P(X\leq 1) = 1- F(1) = 1- 0.0916 = 0.9084.
\]
\end{itemize} 
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Aproximación del modelo Binomial mediante el Poisson}
\framesubtitle{La ley de los casos raros}
En realidad, el modelo de distribución de Poisson surge a partir del modelo de distribución Binomial,  cuando el número de ensayos es muy
grande $n\rightarrow \infty$ y la probabilidad de ``éxito'' es muy pequeña $p\rightarrow 0$.

En tales circunstancias, la variable $X\sim B(n,p)$ puede aproximarse mediante el modelo de distribución de Poisson $P(n\cdot p)$.
\[
\lim_{n\rightarrow \infty, p\rightarrow 0}\binom{n}{x}p^x(1-p)^{n-x} = e^{-\lambda}\frac{\lambda^x}{x!}.
\]

En la práctica, esta aproximación suele utilizarse para $n\geq 30$ y $p\leq 0.1$.

\note{
En realidad, el modelo de distribución de Poisson surge a partir del modelo de distribución Binomial,  cuando el número de ensayos es muy
grande $n\rightarrow \infty$ y la probabilidad de ``éxito'' es muy pequeña $p\rightarrow 0$.

En tales circunstancias, la variable $X\sim B(n,p)$ puede aproximarse mediante el modelo de distribución de Poisson $P(n\cdot p)$.
\[
\lim_{n\rightarrow \infty, p\rightarrow 0}\binom{n}{x}p^x(1-p)^{n-x} = e^{-\lambda}\frac{\lambda^x}{x!}.
\]

En la práctica, esta aproximación suele utilizarse para $n\geq 30$ y $p\leq 0.1$.
}
\end{frame}




%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Aproximación del modelo Binomial mediante el Poisson}
\framesubtitle{Ejemplo}
Se sabe que una vacuna produce una reacción adversa en el 4\% de los casos. Si se vacunan 50 personas, ¿cuál es la probabilidad de que haya
más de 2 personas con reacción adversa?

Está claro que la variable que mide el número de personas con reacción adversa entre las 50 personas vacunadas sigue un modelo de
distribución binomial $X\sim B(50,\,0.04)$, pero como $n=50>30$ y $p=0.04<0.1$, se cumplen las condiciones de la ley de los casos raros y se
puede aproximar mediante una distribución de Poisson $P(50\cdot 0.04)=P(2)$.

Así pues, utilizando la fórmula de la función de probabilidad de la distribución de Poisson, se tiene
\begin{align*}
P(X>2) &= 1 -P(X\leq 2) = 1-f(0)-f(1)-f(2) = 1-e^{-2}\frac{2^0}{0!}-e^{-2}\frac{2^1}{1!}-e^{-2}\frac{2^2}{2!} =\\
&= 1-5e^{-2} = 0.3233.
\end{align*}

\note{
Veamos un ejemplo de cúando aplicar la ley de los casos raros. 

Se sabe que una vacuna produce una reacción adversa en el 4\% de los casos. Si se vacunan 50 personas, ¿cuál es la probabilidad de que haya
más de 2 personas con reacción adversa?

Está claro que la variable que mide el número de personas con reacción adversa entre las 50 personas vacunadas sigue un modelo de
distribución binomial $X\sim B(50,\,0.04)$, pero como $n=50>30$ y $p=0.04<0.1$, se cumplen las condiciones de la ley de los casos raros y se
puede aproximar mediante una distribución de Poisson $P(50\cdot 0.04)=P(2)$.

Así pues, utilizando la fórmula de la función de probabilidad de la distribución de Poisson, se tiene
\begin{align*}
P(X>2) &= 1 -P(X\leq 2) = 1-f(0)-f(1)-f(2) = 1-e^{-2}\frac{2^0}{0!}-e^{-2}\frac{2^1}{1!}-e^{-2}\frac{2^2}{2!} =\\
&= 1-5e^{-2} = 0.3233.
\end{align*}
}
\end{frame}


\subsection{Variables aleatorias continuas}

%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Variables aleatorias continuas}
Las variables aleatorias continuas, a diferencia de las discretas, se caracterizan porque pueden tomar cualquier valor en un intervalo real.
Es decir el conjunto de valores que pueden tomar no sólo es infinito, sino que además es no numerable.

Tal densidad de valores hace imposible el cálculo de las probabilidades de cada uno de ellos, y por tanto no podemos definir los modelos de
distribución de probabilidad por medio de una función de probabilidad como en el caso discreto.

Por otro lado, la medida de una variable aleatoria continua suele estar limitada por las imprecisiones del proceso o instrumento de medida.
Por ejemplo, cuando se dice que una estatura es $1.68$ m, no se está diciendo que es exactamente $1.68$ m, sino que la estatura está entre
$1.675$ y $1.685$ m, ya que el instrumento de medida sólo es capaz de precisar hasta cm.

Así pues, en el caso de variables continuas, \alert{\emph{no tiene sentido medir probabilidades de valores aislados, sino que se medirán
probabilidades de intervalos.}}

\note{
Ya hemos visto cómo estudiar la distribución de probabilidad de variables discretas. Veamos ahora como estudiar las continuas. 

Las variables aleatorias continuas, a diferencia de las discretas, se caracterizan porque pueden tomar cualquier valor en un intervalo real.
Es decir el conjunto de valores que pueden tomar no sólo es infinito, sino que además es no numerable.

Tal densidad de valores hace imposible el cálculo de las probabilidades de cada uno de ellos, y por tanto no podemos definir los modelos de
distribución de probabilidad por medio de una función de probabilidad como en el caso discreto.

Por otro lado, la medida de una variable aleatoria continua suele estar limitada por las imprecisiones del proceso o instrumento de medida.
Por ejemplo, conocer la estatura exacta de una persona es imposible, ya que no se dispone de un instrumento de medida de precisión infinta.
Cuando se dice que una estatura es $1.68$ m, no se está diciendo que es exactamente $1.68$ m, sino que la estatura está entre $1.675$ y
$1.685$ m, ya que el instrumento de medida sólo es capaz de precisar hasta cm.

Así pues, en el caso de variables continuas, \alert{\emph{no tiene sentido medir probabilidades de valores aislados, sino que se medirán
probabilidades de intervalos.}}
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Función de densidad}
Para conocer cómo se distribuye la probabilidad entre los valores de una variable aleatoria continua se utiliza la función de densidad.
\begin{definicion}[Función de densidad]
La \emph{función de densidad} de una variable aleatoria continua $X$ es una función $f(x)$ que cumple las siguientes propiedades:
\begin {itemize}
\item Es no negativa: $f(x)\geq 0$ $\forall x\in \mathbb{R}$,
\item El área acumulada entre la función y el eje de abscisas es 1, es decir,
\[
\int_{-\infty}^{\infty} f(x)\; dx = 1.
\]
\end{itemize}
\end{definicion}
La probabilidad de que la variable tome un valor dentro un intervalo cualquiera $[a,b]$ es
\[
P(a\leq X\leq b) = \int_a^b f(x)\; dx
\] 
\begin{center}
\alert{\emph{¡Ojo! $f(x)$ no es la probabilidad de que la variable tome el valor $x$.}}
\end{center}

\note{
Para conocer cómo se distribuye la probabilidad entre los valores de una variable aleatoria continua se utiliza una función equivalente a
la función de probabilidad de las variables discretas, pero continua. Esta función se conoce como función de densidad y se caracteriza por
\begin {itemize}
\item Es no negativa: $f(x)\geq 0$ $\forall x\in \mathbb{R}$,
\item El área acumulada entre la función y el eje de abscisas es 1, es decir,
\[
\int_{-\infty}^{\infty} f(x)\; dx = 1.
\]
\end{itemize}

La forma de calcular probabilidades a partir de la función de densidad es medir el área que queda por debajo de la función hasta el eje $X$
y por tanto el area total que viene dada por la integral entre $-\infty$ y $\infty$ debe ser 1 que es la probabilidad total. 

De este modo, la probabilidad de que la variable tome un valor dentro un intervalo cualquiera $[a,b]$ es el área que queda por debajo de la
función de densidad en los límites del intervalo y eso es 
\[
P(a\leq X\leq b) = \int_a^b f(x)\; dx
\] 
\begin{center}
\alert{\emph{¡Ojo! a diferencia del caso discreto $f(x)$ no es la probabilidad de que la variable tome el valor $x$, ya que para variables
continuas la probabilidad de un valor aislado es siempre nula.}}
\end{center}
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Función de distribución}
Al igual que para las variables discretas, también tiene sentido medir probabilidades acumuladas por debajo de un determinado valor.
\begin{definicion}[Función de distibución]
La \emph{función de distribución} de una variable aleatoria continua $X$ es una función $F(x)$ que asocia a cada valor
$a$ la probabilidad de que la variable tome un valor menor o igual que dicho valor.
\[
F(a) = P(X\leq a) = \int_{-\infty}^{a} f(x)\; dx.
\] 
\end{definicion} 

\note{
Al igual que para las variables discretas, también tiene sentido medir probabilidades acumuladas por debajo de un determinado valor mediante
la función de distribución, que ahora se define, para un valor $a$ como 
\[
F(a) = P(X\leq a) = \int_{-\infty}^{a} f(x)\; dx.
\] 
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Cálculo de probabilidades como áreas}
La función de densidad nos permite calcular la probabilidad un intervalo $[a,b]$ como el área acumulada por debajo de la función en dicho
intervalo.
\begin{center}
\scalebox{0.55}{\input{img/variables_aleatorias_continuas/calculo_probabilidad_funcion_densidad}}
\end{center}
\[
P(a\leq X\leq b) = \int_a^b f(x)\; dx = F(b) -F(a)
\]

\note{
Como ya hemos dicho, la función de densidad nos permite calcular la probabilidad un intervalo $[a,b]$ como el área acumulada por debajo de
la función en dicho intervalo.

Para ello tenemos dos posibilidades, a partir de la función de la función de densidad, calculando la integral definidad de esta entre $a$ y
$b$ o, a partir de la función de distribución, midiendo el área acumulada por debajo de $b$ y restandole el área acumulada por debajo de $a$
para quedarnos precisamente con el área que hay entre $a$ y $b$. Como es más fácil hacer restas que calcular integrales, trabajaremos la
mayoría de las veces con funciones de distribución. 
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Cálculo de probabilidades como áreas}
\framesubtitle{Ejemplo}
Dada la siguiente función:
\[
f(x) = 
\begin{cases}
0 & \mbox{si $x<0$}\\
e^{-x} & \mbox{si $x\geq 0$},
\end{cases}
\]
veamos que se trata de una función de densidad. Para ello hay que comprobar que es no negativa, lo cual es evidente al tratarse de una función exponencial, y que el área por debajo de ella es 1:
\begin{align*}
\int_{-\infty}^\infty f(x)\;dx &= \int_{-\infty}^0 f(x)\;dx +\int_0^\infty f(x)\;dx = \int_{-\infty}^0 0\;dx +\int_0^\infty e^{-x}\;dx =\\
&= \left[-e^{-x}\right]_0^{\infty} = -e^{-\infty}+e^0 = 1.
\end{align*}
Ahora, a partir de ella, se puede calcular por ejemplo la probabilidad de que la variable tome un valor entre 0 y 2.
\begin{align*}
P(0\leq X\leq 2) &= \int_0^2 f(x)\;dx = \int_0^2 e^{-x}\;dx = \left[-e^{-x}\right]_0^2 = -e^{-2}+e^0 = 0.8646. 
\end{align*}

\note{
Veamos un ejemplo.
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Estadísticos poblacionales}
El cálculo de los estadísticos poblacionales es similar al caso discreto, pero utilizando la función de densidad, en lugar de la función de
probabilidad, y extendiendo la suma discreta a la integral en todo el recorrido de la variable.

Los más importantes son:
\begin{itemize}
\item \structure{Media o esperanza matemática}:
\[
\mu = E(X) = \int_{-\infty}^\infty x f(x)\; dx
\]
\item \structure{Varianza}:
\[
\sigma^2 = Var(X) = \int_{-\infty}^\infty x^2f(x)\; dx -\mu^2
\]
\item \structure{Desviación típica}:
\[
\sigma = +\sqrt{\sigma^2}
\] 
\end{itemize}

\note{
El cálculo de los estadísticos poblacionales es similar al caso discreto, pero utilizando la función de densidad, en lugar de la función de
probabilidad, y extendiendo la suma discreta a la integral en todo el recorrido de la variable.

Así la media se define como 
\begin{itemize}
\item \structure{Media o esperanza matemática}:
\[
\mu = E(X) = \int_{-\infty}^\infty x f(x)\; dx
\]
\item \structure{Varianza}:
\[
\sigma^2 = Var(X) = \int_{-\infty}^\infty x^2f(x)\; dx -\mu^2
\]
\item \structure{Desviación típica}:
\[
\sigma = +\sqrt{\sigma^2}
\] 
\end{itemize}
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Cálculo de los estadísticos poblacionales}
\framesubtitle{Ejemplo}
Sea la función de densidad del ejemplo anterior:
\[
f(x) = 
\begin{cases}
0 & \mbox{si $x<0$}\\
e^{-x} & \mbox{si $x\geq 0$}
\end{cases}
\]
Su media es
\begin{align*}
\mu &= \int_{-\infty}^\infty xf(x)\;dx = \int_{-\infty}^0 xf(x)\;dx +\int_0^\infty xf(x)\;dx = \int_{-\infty}^0 0\;dx +\int_0^\infty xe^{-x}\;dx =\\
&= \left[-e^{-x}(1+x)\right]_0^{\infty} = 1.
\end{align*}
y su varianza vale
\begin{align*}
\sigma^2 &= \int_{-\infty}^\infty x^2f(x)\;dx -\mu^2 = \int_{-\infty}^0 x^2f(x)\;dx +\int_0^\infty x^2f(x)\;dx -\mu^2 = \\
&= \int_{-\infty}^0 0\;dx +\int_0^\infty x^2e^{-x}\;dx -\mu^2= \left[-e^{-x}(x^2+2x+2)\right]_0^{\infty} - 1^2= 2e^0-1 = 1.
\end{align*}

\note{
Siguiendo con el ejemplo anterior, la media vale:
}
\end{frame}



%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Modelos de distribución continuos}
Existen varios modelos de distribución de probabilidad que aparecen bastante a menudo en la naturaleza y también como consecuencia de los
procesos de muestreo aleatorio simple.

A continuación veremos los más importantes:
\begin{itemize}
\item Distribución Uniforme continua.
\item Distribución Normal.
\item Distribución T de Student.
\item Distribución Chi-cuadrado.
\item Distribución F de Fisher-Snedecor.
\end{itemize}

\note{
Existen varios modelos de distribución de probabilidad que aparecen bastante a menudo en la naturaleza y también como consecuencia de los
procesos de muestreo aleatorio simple.

A continuación veremos los más importantes:
\begin{itemize}
\item Distribución Uniforme continua.
\item Distribución Normal.
\item Distribución T de Student.
\item Distribución Chi-cuadrado.
\item Distribución F de Fisher-Snedecor.
\end{itemize}
}
\end{frame}


\subsection{Distribución Uniforme continua}

%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Distribución Uniforme continua $U(a,b)$}
Cuando todos los valores de una variable continua son equiprobables, se dice que la variable sigue un \emph{modelo de distribución uniforme
continuo}.
\begin{definicion}[Distribución Uniforme continua]
Una variable aleatoria continua $X$, cuyo recorrido es el intervalo $[a,b]$, sigue un modelo de distribución \emph{uniforme} $U(a,b)$, si todos los valores de la variable son equiprobables, y por tanto, su función de densidad es constante en todo el intervalo:
\[
f(x)= \frac{1}{b-a}\quad \forall x\in [a,b]
\]
\end{definicion}

Su media y varianza valen
\[
\mu = \frac{a+b}{2}\qquad \sigma^2=\frac{(b-a)^2}{12}.
\]

\note{
Al igual que para variables discretas, cuando todos los valores de una variable continua son equiprobables, se dice que la variable sigue
un \emph{modelo de distribución uniforme continuo}.

Si el recorrido de la variable es el intervalo $[a,b]$ entonces se dice que sigue un modelo de distribución \emph{uniforme} $U(a,b)$, y se
cumple que su función de densidad es constante y vale:
\[
f(x)= \frac{1}{b-a}\quad \forall x\in [a,b]
\]

Además, su media vale
\[
\mu = \frac{a+b}{2}.
\]
y su varianza
\[
\sigma^2=\frac{(b-a)^2}{12}.
\]
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Función de densidad de la Uniforme continua $U(a,b)$}
La generación aleatoria de un número real entre 0 y 1 sigue un modelo de distribución uniforme continuo $U(0,1)$. 
\begin{center}
\scalebox{0.7}{\input{img/variables_aleatorias_continuas/funcion_densidad_uniforme}}
\end{center}

\note{
Un ejemplo de variable aleatoria uniforme continua sería la que mide el resultado de generar aleatoriamente un número entre 0 y 1. Esta
variable seguiría un modelo de distribución uniforme continuo $U(0,1)$, y la gráfica de su función de densidad es esta. Como se ve, la
función es constante y vale 1, ya que debe cumplirse, al ser función de densidad, que el área total por debajo de ella debe ser 1, y como en
realidad se trata del área de un rectángulo de base 1, pues la altura debe ser también 1.
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Función de distribución de la Uniforme continua $U(a,b)$}
Como la función de densidad es constante, la función de distribución presenta un crecimiento lineal.
\begin{center}
\scalebox{0.7}{\input{img/variables_aleatorias_continuas/funcion_distribucion_uniforme}}
\end{center}

\note{
En esta otra gráfica tenemos la función de distribución $U(0,1)$.
Como la función de densidad es constante, la función de distribución presenta un crecimiento lineal. Obsérvese que, como para cualquier
función de distribución, la probabilidad acumulada al comienzo del recorrido es 0, y al final, vale 1, que es la probabilidad total. 
}
\end{frame}


% ---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Cálculo de probabilidades con una Uniforme continua}
\framesubtitle{Ejemplo de espera de un autobús}
Supóngase que un autobús pasa por una parada cada 15 minutos. Si una persona puede llegar a la parada en cualquier instante, \emph{¿cuál es
la probabilidad de que espere entre 5 y 10 minutos?}
\begin{columns}
\begin{column}{0.52\textwidth}
En este caso, la variable $X$ que mide el tiempo de espera sigue un modelo de distribución uniforme continua $U(0,15)$ ya que cualquier
valor entre los 0 y los 15 minutos es equipobrable.

Así pues, la probabilidad que nos piden es
\begin{align*}
P(5\leq X\leq 10) &= \int_{5}^{10} \frac{1}{15}\;dx = \left[\frac{x}{15}\right]_5^{10} = \\
&= \frac{10}{15}-\frac{5}{15} =\frac{1}{3}.
\end{align*}
\end{column}
\begin{column}{0.43\textwidth}
\begin{center}
\scalebox{0.5}{\input{img/variables_aleatorias_continuas/calculo_probabilidades_uniforme}}
\end{center}
\end{column}
\end{columns}
Además, el tiempo medio de espera será $\mu=\frac{0+15}{2}=7.5$ minutos.

\note{
Como ejemplo, supóngase que un autobús pasa por una parada cada 15 minutos. Si una persona puede llegar a la parada en cualquier instante,
\emph{¿cuál es la probabilidad de que espere entre 5 y 10 minutos?}

Está claro que lo mínimo que puede esperar una persona es 0 minutos, si llega justo cuando está el autobús, y lo máximo es 15 minutos, si
llega justo cuando el autobús se marcha. Como además puede llegar en cualquier instante con equiprobabiliadad, la variable $X$ que mide el
tiempo de espera sigue un modelo de distribución uniforme continua $U(0,15)$.

Así pues, la probabilidad que nos piden es
\begin{align*}
P(5\leq X\leq 10) &= \int_{5}^{10} \frac{1}{15}\;dx = \left[\frac{x}{15}\right]_5^{10} = \\
&= \frac{10}{15}-\frac{5}{15} =\frac{1}{3}.
\end{align*}

Aunque también podría calcularse fácilmente a partir de la gráfica de la función de densidad que es constante y vale $1/15$, midiendo el
área que queda por debajo de esta función entre 5 y 10. Como se tráta del área de un rectánculo, basta multiplicar la base, que es 5, por la
altura que es $1/15$ y de nuevo se obtiene $1/3$.
}
\end{frame}


\subsection{Distribución Normal}

%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Distribución Normal $N(\mu,\sigma)$}
El modelo de distribución normal es, sin duda, el modelo de distribución continuo más importante, ya que es el que más a menudo se presenta
en la naturaleza.
\begin{definicion}[Distribución Normal]
Una variable aleatoria continua $X$ sigue un modelo de distribución \emph{normal} $N(\mu,\sigma)$ si su recorrido es $\mathbb{R}$ y su función de densidad vale
\[
f(x)= \frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}.
\]
\end{definicion}

La distribución normal depende de dos parámetros $\mu$ y $\sigma$ que son, precisamente, su media y desviación típica.

\note{
El modelo de distribución normal es, sin duda, el modelo de distribución continuo más importante, ya que es el que más a menudo se presenta
en la naturaleza, sobre todo en variables continuas biológicas.

\begin{definicion}[Distribución Normal]
Una variable aleatoria continua $X$ sigue un modelo de distribución \emph{normal} $N(\mu,\sigma)$ si su recorrido es $\mathbb{R}$ y su función de densidad vale
\[
f(x)= \frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}.
\]
\end{definicion}

La distribución normal depende de dos parámetros $\mu$ y $\sigma$ que son, precisamente, su media y desviación típica.
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Función de densidad de la Normal $N(\mu,\sigma)$}
La gráfica de la función de densidad de la distribución normal tiene forma de una especie de campana, conocida como \emph{campana de Gauss}
(en honor a su descubridor), y está centrada en la media $\mu$.
\begin{center}
\scalebox{0.65}{\input{img/variables_aleatorias_continuas/funcion_densidad_normal}}
\end{center}

\note{
La gráfica de la función de densidad de la distribución normal tiene forma de una especie de campana, conocida como \emph{campana de Gauss}
(en honor a su descubridor), y está centrada en la media $\mu$.
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Función de densidad de la Normal $N(\mu,\sigma)$}
La forma de la campana de Gauss depende de sus dos parámetros:
\begin{itemize}
\item La media $\mu$ determina dónde está centrada.
\item La desviación típica $\sigma$ determina su anchura.
\end{itemize} 
\begin{center}
\scalebox{0.5}{\input{img/variables_aleatorias_continuas/funcion_densidad_normales_distinta_media}}
\quad
\scalebox{0.5}{\input{img/variables_aleatorias_continuas/funcion_densidad_normales_distinta_varianza}}
\end{center}

\note{
La forma de la campana de Gauss depende de sus dos parámetros:
\begin{itemize}
\item Por un lado, ya hemos visto que la media $\mu$ determina dónde está centrada. En la gráfica de la izquierda podemos ver las funciones
de densidad de dos normales, una con media 0 y desviación típica 1, y otra con media 2 y desviación típica 1. Como se ve, ambas gráficas son
idénticas, salvo que la primera está centrada en el 0 y la segunda en el 2.
\item Por otro lado, la desviación típica $\sigma$, al ser una medida de la dispersión de la población, determina su anchura. En la gráfica
de la derecha podemos ver las funciones de densidad de dos normales con la misma media 0, y desviaciones típicas 1, y 2 respectivamente.
Como se ve, ambas están centradas en el 0, pero la primera es más estrecha que la segunda al tener menos dispersión. 
\end{itemize} 
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Función de distribución de la Normal $N(\mu,\sigma)$}
Por su parte, la gráfica de la función de distribución tiene forma de S. 
\begin{center}
\scalebox{0.7}{\input{img/variables_aleatorias_continuas/funcion_distribucion_normal}}
\end{center}

\note{
Por su parte, la gráfica de la función de distribución de una normal siempre tiene forma de S. 
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Propiedades de la distribución Normal}
\begin{itemize}
\item La función de densidad es simétrica respecto a la media y por tanto, su coeficiente de asimetría es $g_1=0$.
\item También es mesocúrtica, y por tanto, su coeficiente de apuntamiento vale $g_2=0$.
\item La media, la mediana y la moda coinciden
\[
\mu = Me = Mo.
\]
\item Tiende asintóticamente a 0 cuando $x$ tiende a $\pm \infty$.
\end{itemize}

\note{
La distribución normal tiene propiedades muy interesantes:
\begin{itemize}
\item La función de densidad es simétrica respecto a la media y por tanto, su coeficiente de asimetría es $g_1=0$.
\item También es mesocúrtica, y por tanto, su coeficiente de apuntamiento vale $g_2=0$. Recordemos que el apuntamiento de cualquier variable
se compara precisamente con el apuntamiento de la distribución normal, ya que al ser esta la distribución más común, se toma como
referencia.
\item De nuevo, al ser simétrica con respecto a la media, hasta la media tendremos acumulada la mitad de la probabilidad, y por tanto la
media coincide con la mediana, y también con la moda, ya que sobre la media se alcanza el máximo de la función de densidad.
\[
\mu = Me = Mo.
\]
\item Tiende asintóticamente a 0 cuando $x$ tiende a $\pm \infty$.
\end{itemize}
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Propiedades de la distribución Normal}
\begin{itemize}
\item Se cumple que
\begin{align*}
& P(\mu-\sigma \leq X \leq \mu+\sigma) = 0.68,\\
& P(\mu-2\sigma \leq X \leq \mu+2\sigma) = 0.95,\\
& P(\mu-3\sigma \leq X \leq \mu+3\sigma) = 0.99.
\end{align*}
\end{itemize}
\begin{center}
\scalebox{0.6}{\input{img/variables_aleatorias_continuas/propiedades_normal}}
\end{center}

\note{
Y también se cumple que
\begin{align*}
& P(\mu-\sigma \leq X \leq \mu+\sigma) = 0.68,\\
& P(\mu-2\sigma \leq X \leq \mu+2\sigma) = 0.95,\\
& P(\mu-3\sigma \leq X \leq \mu+3\sigma) = 0.99.
\end{align*}
}
es decir, casi la totalidad de los individuos de la población presentarán valores entre la media menos tres veces la desviación típica, y la
media mas tres veces la desviación típica.
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Propiedades de la distribución Normal}
\framesubtitle{Ejemplo}
En un estudio se ha comprobado que el nivel de colesterol total en mujeres
sanas de entre 40 y 50 años sigue una distribución normal de media de 210 mg/dl y desviación
típica 20 mg/dl. 
\emph{¿Qué quiere decir esto?}

Atendiendo a las propiedades de la campana de Gauss, se tiene que 
\begin{itemize}
\item El 68\% de las mujeres sanas tendrán el colesterol entre $210\pm 20$ mg/dl, es decir, entre 190 y 230 mg/dl.
\item El 95\% de las mujeres sanas tendrán el colesterol entre $210\pm 2\cdot 20$ mg/dl, es decir, entre 170 y 250
mg/dl.
\item El 99\% de las mujeres sanas tendrán el colesterol entre $210\pm 3\cdot 20$ mg/dl, es decir, entre 150 y 270
mg/dl.
\end{itemize}

En la analítica sanguínea suele utilizarse el intervalo $\mu\pm 2\sigma$ para detectar posibles patologías. En el caso
del coresterol, dicho intervalo es $[170\text{ mg/dl}, 250\text{ mg/dl}]$. Cuando una persona tiene el colesterol fuera
de estos límites, se tiende a pensar que tiene alguna patología, aunque ciertamente podría estar sana, pero la
probabilidad de que eso ocurra es sólo de un 5\%.

\note{
Veamos una aplicación de estas propiedades. 

En un estudio se ha comprobado que el nivel de colesterol total en mujeres sanas de entre 40 y 50 años sigue una distribución normal de
media de 210 mg/dl y desviación típica 20 mg/dl. 
\emph{¿Qué quiere decir esto?}

Atendiendo a las propiedades de la campana de Gauss, se tiene que 
\begin{itemize}
\item El 68\% de las mujeres sanas tendrán el colesterol entre $210\pm 20$ mg/dl, es decir, entre 190 y 230 mg/dl.
\item El 95\% de las mujeres sanas tendrán el colesterol entre $210\pm 2\cdot 20$ mg/dl, es decir, entre 170 y 250
mg/dl.
\item El 99\% de las mujeres sanas tendrán el colesterol entre $210\pm 3\cdot 20$ mg/dl, es decir, entre 150 y 270
mg/dl.
\end{itemize}

En la analítica sanguínea suele utilizarse el intervalo $\mu\pm 2\sigma$ para detectar posibles patologías. En el caso
del coresterol, dicho intervalo es $[170\text{ mg/dl}, 250\text{ mg/dl}]$. Cuando una persona tiene el colesterol fuera
de estos límites, se tiende a pensar que tiene alguna patología, aunque ciertamente podría estar sana, pero la
probabilidad de que eso ocurra es sólo de un 5\%.
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{El teorema central del límite}
El comportamiento anterior lo presentan muchas variables continuas físicas y biológicas.

Si se piensa por ejemplo en la distribución de las estaturas, se verá que la mayor parte de los individuos presentan estaturas en torno a la
media, tanto por arriba, como por debajo, pero que a medida que van alejándose de la media, cada vez hay menos individuos con dichas
estaturas.

La justificación de que la distribución normal aparezca de manera tan frecuente en la naturaleza la encontramos en el
\structure{\textbf{teorema central del límite}}, que veremos más adelante, y que establece que si una variable aleatoria $X$ proviene de un
experimento aleatorio cuyos resultados son debidos a un conjunto muy grande de causas independientes que actúan sumando sus efectos,
entonces $X$ sigue una distribución aproximadamente normal.

\note{
Se ha observado que la mayor parte de las variables continuas físicas y biológicas presentan una distribucón con forma de campana de Gauss.

Si se piensa por ejemplo en la distribución de las estaturas, se verá que la mayor parte de los individuos presentan estaturas en torno a la
media, tanto por arriba, como por debajo, pero que a medida que van alejándose de la media, cada vez hay menos individuos con dichas
estaturas.

La justificación de que la distribución normal aparezca de manera tan frecuente en la naturaleza la encontramos en el
\structure{\textbf{teorema central del límite}}, que veremos más detenidamente en el siguiente tema, y que establece que si una variable
aleatoria $X$ proviene de un experimento aleatorio cuyos resultados son debidos a un conjunto muy grande de causas independientes que actúan
sumando sus efectos, entonces $X$ sigue una distribución aproximadamente normal.

Si pensamos en cualquier variable biológica, como por ejemplo la tensión arterial, rápidamente podremos identificar multitud de factores que
influyen en ella, como por ejemplo la edad, el sexo, la dieta, el ejercicio físico, si se fuma o no, etc. El valor de la tensión arterial en
un individuo es el resultado de todos estos factores que suman sus efectos de manera independiente, y por ello, el el colesterol acaba
teniendo una distribución normal.
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{La distribución Normal estándar $N(0,1)$}
De todas las distribuciones normales, la más importante es la que tiene media $\mu=0$ y desviación típica $\sigma=1$,
que se conoce como \structure{\textbf{normal estándar}} y se designa por $Z$.
\begin{center}
\scalebox{0.65}{\input{img/variables_aleatorias_continuas/funcion_densidad_normal_estandar}}
\end{center}

\note{
De todas las distribuciones normales, la más importante es la que tiene media $\mu=0$ y desviación típica $\sigma=1$,
que se conoce como \structure{\textbf{normal estándar}} y se designa por $Z$.

Su función de densidad será una campana de Gauss centrada en el 0, en la que el 99\% de los individuos estarán entre -3 y 3. 
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Cálculo de probabilidades con la Normal estándar}
\framesubtitle{Manejo de la tabla de la función de distribución}
Para evitar tener que calcular probabilidades integrando la función de densidad de la normal estándar se suele utilizar su función de
distribución.

Habitualmente se suele manejar una tabla con los valores de la función de distribución tabulados cada centésima. 
\begin{columns}
\begin{column}{0.47\textwidth}
\begin{center}
Ejemplo $P(Z\leq 0.52)$

\scalebox{0.8}{\input{img/variables_aleatorias_continuas/tabla_normal}}

$0.52 \rightarrow $ fila $0.5$ + columna $0.02$
\end{center}
\end{column}
\begin{column}{0.53\textwidth}
\scalebox{0.6}{\input{img/variables_aleatorias_continuas/calculo_probabilidades_normal_estandar}}
\end{column}
\end{columns}

\note{
Para evitar tener que calcular probabilidades integrando la función de densidad de la normal estándar se suele utilizar su función de
distribución.

Habitualmente se suele manejar una tabla con los valores de la función de distribución tabulados cada centésima. En esta tabla, la primera
columna contiene las décimas y la primera fila las centésimas, de forma que si por ejemplo queremos medir la probabilidad acumulada hasta el
$0.52$, tenemos que ir hasta la casilla correspondiente a la fila $0.5$  (5 décimas) y hasta la columna $0.02$ (2 centésimas), donde aparece
la probabilidad acumulada $0.6985$ y esta sería el área que queda por debajo de la campana de Gauss de la normal estándar entre $-\infty$ y
$0.52$.
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Cálculo de probabilidades con la Normal estándar}
\framesubtitle{Probabilidades acumuladas por encima de un valor}
Cuando tengamos que calcular probabilidades acumuladas por encima de un determinado valor, podemos hacerlo por medio de la probabilidad del
suceso contrario.

Por ejemplo
\[
P(Z>0.52) =1-P(Z\leq 0.52) = 1-F(0.52) = 1 - 0.6985 = 0.3015.
\]
\begin{center}
\scalebox{0.55}{\input{img/variables_aleatorias_continuas/calculo_probabilidades_derecha_normal_estandar}}
\end{center}

\note{
Cuando tengamos que calcular probabilidades acumuladas por encima de un determinado valor, podemos hacerlo por medio de la probabilidad del
suceso contrario, ya que la función de distribución siempre mide probabilidades acumuladas por debajo de cada valor. 

Así, la probabilidad acumulada por encima de $0.52$, será 1 menos la probabilidad acumulada por debajo de dicho valor, que como hemos visto
en la tabla, valía $0.6985$, lo que nos da $0.3015$. Esto es lógico, ya que si el área total por debajo de la campana de Gauss es 1, el área
acumulada por encima de $0.52$ será 1 menos el área que quede por debajo de este valor. 
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Tipificación}
Ya se ha visto cómo calcular probabilidades con una distribución normal estándar, pero \emph{¿qué hacer cuando la
distribución normal no es la estándar?}

Afortunadamente, siempre se puede transformar una variable normal para convertirla en una normal estándar. 
\begin{teorema}[Tipificación]
Si $X$ es una variable normal de media $\mu$ y desviación típica $\sigma$, entonces la variable resultante de restarle a $X$ su media y
dividir por su desviación típica, sigue un modelo de distribución normal estándar:
\[
X\sim N(\mu,\sigma) \Rightarrow Z=\frac{X-\mu}{\sigma}\sim N(0,1).
\]
Esta transformación lineal se conoce como \emph{transformación de tipificación} y la variable resultante $Z$ se conoce como \emph{normal
tipificada}.
\end{teorema} 

Así pues, para calcular probabilidades de una variable normal que no sea la normal estándar, se aplica primero la transformación de
tipificación y después se puede utilizar la función de distribución de la normal estándar.

\note{
Ya se ha visto cómo calcular probabilidades con una distribución normal estándar, pero \emph{¿qué hacer cuando la
distribución normal no es la estándar?}

Afortunadamente, siempre se puede transformar una variable normal para convertirla en una normal estándar tipificándola.
\begin{teorema}[Tipificación]
Si $X$ es una variable normal de media $\mu$ y desviación típica $\sigma$, entonces la variable resultante de restarle a $X$ su media y
dividir por su desviación típica, sigue un modelo de distribución normal estándar:
\[
X\sim N(\mu,\sigma) \Rightarrow Z=\frac{X-\mu}{\sigma}\sim N(0,1).
\]
Esta transformación lineal se conoce como \emph{transformación de tipificación} y la variable resultante $Z$ se conoce como \emph{normal
tipificada}.
\end{teorema} 

Así pues, para calcular probabilidades de una variable normal que no sea la normal estándar, tendremos que aplicar la transformación de
tipificación primero y después se puede utilizar la tabla de la función de distribución de la normal estándar.
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Cálculo de probabilidades tipificando}
\framesubtitle{Ejemplo}
Supóngase que la nota de un examen sigue un modelo de distribución de probabilidad normal $N(\mu=6,\sigma=1.5)$. \emph{¿Qué porcentaje de
suspensos habrá en la población?}

Para responder a esta pregunta necesitamos calcular la probabilidad $P(X<5)$. Como $X$ no es la normal estándar, se le aplica la
transformación de tipificación $Z=\displaymath \frac{X-\mu}{\sigma} = \frac{X-6}{1.5}$:
\[
P(X<5) = P\left(\frac{X-6}{1.5}<\frac{5-6}{1.5}\right) = P(Z<-0.67).
\]
Después se mira en la tabla de la función de distribución de la normal estándar:
\[
P(Z<-0.67) = F(-0.67) = 0.2514.
\]

Así pues, habrán suspendido el $25.14\%$ de los alumnos. 

\note{
Veamos un ejemplo. 

Supóngase que la nota de un examen sigue un modelo de distribución de probabilidad normal $N(\mu=6,\sigma=1.5)$. \emph{¿Qué porcentaje de
suspensos habrá en la población?}

Para responder a esta pregunta necesitamos calcular la probabilidad de que la nota sea inferior a 5. Como $X$ no es la normal estándar, se
le aplica la transformación de tipificación, que es $Z=\displaymath \frac{X-\mu}{\sigma} = \frac{X-6}{1.5}$. Por tanto, 
\[
P(X<5) = P\left(\frac{X-6}{1.5}<\frac{5-6}{1.5}\right) = P(Z<-0.67).
\]
Después sólo queda mirar en tabla de la función de distribución de la normal estándar y observar que la probabilidad acumulada hasta el
$-0.67$ es $0.2514$.

Así pues, habrán suspendido el $25.14\%$ de los alumnos. 
}
\end{frame}


\subsection{Distribución Chi-cuadrado}

%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Distribución chi-cuadrado $\chi^2(n)$}
\begin{definicion}[Distribución chi-cuadrado $\chi^2(n)$]
Si  $Z_1,\ldots,Z_n$ son $n$ variables aleatorias normales estándar independientes, entonces la suma de sus cuadrados sigue un modelo de
distribución \emph{chi-cuadrado de $n$ grados de libertad}:
\[
\chi^2(n) = Z_1^2+\cdots +Z_n^2.
\]
\end{definicion}
Su recorrido es  $\mathbb{R}^+$ y su media y varianza valen
\[
\mu = n, \qquad \sigma^2 = 2n.
\]
Como se verá más adelante, la distribución chi-cuadrado juega un papel importante en la estimación de la varianza poblacional y en el
estudio de la relación entre variables cualitativas.

\note{
Las distribuciones que veremos a continuación son distribuciones que siguen algunos de los estadísticos observados en las muestras
aleatorias. Su principal utilidad se verá en el siguiente tema.

El primer modelo de distribución es el modelo chi-cuadrado.

Si  $Z_1,\ldots,Z_n$ son $n$ variables aleatorias normales estándar independientes, entonces
la suma de sus cuadrados sigue un modelo de distribución \emph{chi-cuadrado de $n$ grados de libertad}:
\[
\chi^2(n) = Z_1^2+\cdots +Z_n^2.
\]

Se cumple que su recorrido es  $\mathbb{R}^+$, su media vale $\mu=n$ y su varianza vale $\sigma^2 = 2n$.

Como se verá más adelante, la distribución chi-cuadrado juega un papel importante en la estimación de la varianza poblacional y en el
estudio de la relación entre variables cualitativas.
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Función de densidad de la distribución chi-cuadrado}

\begin{center}
\scalebox{0.8}{\input{img/variables_aleatorias_continuas/funcion_densidad_chi_cuadrado}}
\end{center}

\note{
Aquí tenemos las gráfica de la función de densidad de varias distribuciones chi-cuadrado con distintos grados de libertad. Como se puede
apreciar, esta distribución, por ser la suma de cuadrados, no presenta valores negativos, y a diferencia de la normal, siempre es asimétrica
hacia la izquierda.
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Propiedades de la distribución chi-cuadrado $\chi^2(n)$}
\begin{itemize}
\item No toma valores negativos.
\item Si $X\sim \chi^2(n)$ e $Y\sim \chi^2(m)$, entonces
\[
X+Y \sim \chi^2(n+m).
\]
\item Al aumentar el número de grados de libertad, se aproxima asintóticamente a una normal.
\end{itemize}

\note{
Algunas propiedades que tiene la distribución chi-cuadrado son:
\begin{itemize}
\item No toma valores negativos.
\item Si $X\sim \chi^2(n)$ e $Y\sim \chi^2(m)$, entonces
\[
X+Y \sim \chi^2(n+m).
\]
\item Al aumentar el número de grados de libertad, se aproxima asintóticamente a una normal.
\end{itemize}
}
\end{frame}


\subsection{Distribución T de Student}

%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Distribución T de Student $T(n)$}
\begin{definicion}[Distribución T de Student $T(n)$]
Si  $Z\sim N(0,1)$ es una variable aleatoria normal estándar y $X\sim \chi^2(n)$ es una variable aleatoria chi-cuadrado de $n$ grados de
libertad, ambas independientes, entonces la variable
\[
T = \frac{Z}{\sqrt{X/n}},
\]
sigue un modelo de distribución \emph{T de Student de $n$ grados de libertad}.
\end{definicion}

Su recorrido es $\mathbb{R}$ y su media y varianza valen
\[
\mu = 0, \qquad \sigma^2 = \frac{n}{n-2} \mbox{ si $n>2$}.
\]

Como se verá más adelante, la distribución T de Student juega un papel importante en la estimación la media poblacional.

\note{
\begin{definicion}[Distribución T de Student $T(n)$]
Si  $Z\sim N(0,1)$ es una variable aleatoria normal estándar y $X\sim \chi^2(n)$ es una variable aleatoria chi-cuadrado de $n$ grados de
libertad, ambas independientes, entonces la variable
\[
T = \frac{Z}{\sqrt{X/n}},
\]
sigue un modelo de distribución \emph{T de Student de $n$ grados de libertad}.
\end{definicion}

Se cumple que su recorrido es $\mathbb{R}$ y su media vale $\mu=0$ y su varianza vale
\[
\sigma^2 = \frac{n}{n-2} \mbox{ si $n>2$}.
\]

Como se verá más adelante, la distribución T de Student juega un papel importante en la estimación la media poblacional.
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Función de densidad de la distribución T de Student}

\begin{center}
\scalebox{0.8}{\input{img/variables_aleatorias_continuas/funcion_densidad_t_student}}
\end{center}

\note{
Aquí tenemos las gráfica de la función de densidad de varias distribuciones T de student con distintos grados de libertad. Como se puede
apreciar, esta distribución está centrada en el 0 y es muy parecida a la normal estándar, aunque un poco más platicúrtica. 
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Propiedades de la distribución T de Student $T(n)$}
\begin{itemize}
\item Es simétrica con respecto a su media $\mu=0$.
\item Es muy similar a la normal estándar, pero algo más platicúrtica. Además, a medida que aumentan los grados de libertad, la gráfica de la distribución tiende hacia la de la normal estándar, hasta llegar a ser prácticamente iguales para $n\geq 30$.
\[
T(n)\stackrel{n\rightarrow \infty}{\approx}N(0,1).
\]
\end{itemize}

\note{
Algunas propiedades que tiene la distribución T de student son:
\begin{itemize}
\item Es simétrica con respecto a su media $\mu=0$.
\item Como ya hemos dicho, es muy similar a la normal estándar, pero algo más platicúrtica. Además, a medida que aumentan los grados de
libertad, la gráfica de la distribución tiende hacia la de la normal estándar, hasta llegar a ser prácticamente iguales para $n\geq 30$.
\[
T(n)\stackrel{n\rightarrow \infty}{\approx}N(0,1).
\]
\end{itemize}
}
\end{frame}


\subsection{Distribución F de Fisher-Snedecor}

%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Distribución F de Fisher-Snedecor $F(m,n)$}
\begin{definicion}[Distribución F de Fisher-Snedecor $F(m,n)$]
Si  $X\sim \chi^2(m)$ es una variable aleatoria chi-cuadrado de $m$ grados de libertad e $Y\sim \chi^2(n)$ es otra variable aleatoria
chi-cuadrado de $n$ grados de libertad, ambas independientes, entonces la variable
\[
F = \frac{X/m}{Y/n},
\]
sigue un modelo de distribución \emph{F de Fisher-Snedecor de $m$ y $n$ grados de libertad}.
\end{definicion}

Su recorrido es $\mathbb{R}^+$ y su media y varianza valen
\[
\mu = \frac{n}{n-2}, \qquad \sigma^2 =\frac{2n^2(m+n−2)}{m(n-2)^2(n-4)}\mbox{ si $n>4$}.
\]

Como se verá más adelante, la distribución F de Fisher-Snedecor juega un papel importante en la comparación de varianzas poblacionales y en
el análisis de la varianza.

\note{
\begin{definicion}[Distribución F de Fisher-Snedecor $F(m,n)$]
Si  $X\sim \chi^2(m)$ es una variable aleatoria chi-cuadrado de $m$ grados de libertad e $Y\sim \chi^2(n)$ es otra variable aleatoria
chi-cuadrado de $n$ grados de libertad, ambas independientes, entonces la variable
\[
F = \frac{X/m}{Y/n},
\]
sigue un modelo de distribución \emph{F de Fisher-Snedecor de $m$ y $n$ grados de libertad}.
\end{definicion}

Se cumple que su recorrido es $\mathbb{R}^+$ y su media vale
\[
\mu = \frac{n}{n-2},
\]
y su varianza 
\[
\sigma^2 =\frac{2n^2(m+n−2)}{m(n-2)^2(n-4)}\mbox{ si $n>4$}.
\]

Como se verá más adelante, la distribución F de Fisher-Snedecor juega un papel importante en la comparación de varianzas poblacionales y en
el análisis de la varianza.
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Función de densidad de la distribución F de Fisher-Snedecor $F(m,n)$}

\begin{center}
\scalebox{0.75}{\input{img/variables_aleatorias_continuas/funcion_densidad_f_fisher}}
\end{center}

\note{
Aquí tenemos las gráfica de la función de densidad de varias distribuciones F de Fisher con distintos grados de libertad. Como se puede
apreciar, al igual que la distribución chi-cuadrado, no presenta valores negativos, y siempre es asimétrica hacia la izquierda.
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Propiedades de la distribución F de Fisher-Snedecor $F(m,n)$}
\begin{itemize}
\item No está definida para valores negativos.
\item De la definición se deduce que
\[
F(m,n) =\frac{1}{F(n,m)}
\]
de manera que si llamamos $f(m,n)_p$ al valor que cumple que $P(F(m,n)≤f(m,n)_p)=p$, entonces se cumple
\[                                          
f(m,n)_p =\frac{1}{f(n,m)_{1−p}}
\]
Esto resulta muy útil para utilizar las tablas de su función de distribución.
\end{itemize}

\note{
Algunas propiedades que tiene la distribución F de Fisher son:
\begin{itemize}
\item No está definida para valores negativos.
\item De la definición se deduce que
\[
F(m,n) =\frac{1}{F(n,m)}
\]
de manera que si llamamos $f(m,n)_p$ al valor que cumple que $P(F(m,n)≤f(m,n)_p)=p$, entonces se cumple
\[                                          
f(m,n)_p =\frac{1}{f(n,m)_{1−p}}
\]
Esto resulta muy útil para utilizar las tablas de su función de distribución.
\end{itemize}
}
\end{frame}
