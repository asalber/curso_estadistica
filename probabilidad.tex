\section{Teoría de la Probabilidad}

\mode<presentation>{
%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Teoría de la  Probabilidad}
\tableofcontents[sectionstyle=show/hide,hideothersubsections]
\end{frame}
}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Introducción}
La estadística descriptiva permite describir el comportamiento y las relaciones entre las variables en la muestra, pero no permite sacar
conclusiones sobre el resto de la población.

Ha llegado el momento de dar el salto de la muestra a la población y pasar de la estadística descriptiva a la inferencia estadística, y el
puente que lo permite es la \structure{\textbf{teoría de la probabilidad}}.

Hay que tener en cuenta que el conocimiento que se puede obtener de la población a partir de la muestra es limitado, pero resulta evidente
que la aproximación a la realidad de la población será mejor cuanto más representativa sea la muestra de ésta. Y recordemos que para que la
muestra sea representativa de la población deben utilizarse técnicas de muestreo aleatorio, es decir, en la que los individuos se
seleccionen al \emph{azar}.

La teoría de la probabilidad precisamente se encarga de controlar ese azar para saber hasta qué punto son fiables las conclusiones obtenidas
a partir de una muestra.

\note{La estadística descriptiva permite describir el comportamiento y las relaciones entre las variables en la muestra, pero no permite sacar
conclusiones sobre el resto de la población.

Ha llegado el momento de dar el salto de la muestra a la población y pasar de la estadística descriptiva a la inferencia estadística, y el
puente que lo permite es la \structure{\textbf{teoría de la probabilidad}}.

Hay que tener en cuenta que el conocimiento que se puede obtener de la población a partir de la muestra es limitado, pero resulta evidente que la aproximación a la realidad de la población será mejor
cuanto más representativa sea la muestra de ésta. Y recordemos que para que la muestra sea representativa de la población deben utilizarse técnicas de muestreo aleatorio, es decir, en la que los individuos se
seleccionen al \emph{azar}.

Es aquí por tanto donde se necesita la teoría de la probabilidad, ya que esta precisamente se encarga de controlar ese azar para
saber hasta qué punto son fiables las conclusiones obtenidas a partir de una muestra.
}
\end{frame}


\subsection{Experimentos y sucesos aleatorios}

%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Experimentos y sucesos aleatorios}
El estudio de una característica en una población se realiza a través de experimentos aleatorios.

\begin{definicion}[Experimento aleatorio] Un \emph{experimento aleatorio} es aquel en el que se conoce cuál es el conjunto de resultados
posibles antes de su realización pero se desconoce cuál será el resultado concreto del mismo.
\end{definicion}

Un ejemplo sencillo de experimentos aleatorios son los juegos de azar. Por ejemplo, el lanzamiento de un dado es un experimento aleatorio ya
que:
\begin{itemize}
\item Se conoce el conjunto posibles de resultados $\{1,2,3,4,5,6\}$.
\item Antes de lanzar el dado, es imposible predecir con absoluta certeza el valor que saldrá. 
\end{itemize}

Otro ejemplo de experimento aleatorio sería la selección de un individuo de una población al azar y la determinación de su grupo sanguíneo.

En general, la obtención de cualquier muestra mediante procedimientos aleatorios será un experimento aleatorio.  

\note{El estudio de una característica en una población se realiza a través de experimentos aleatorios.

\begin{definicion}[Experimento aleatorio] Un \emph{experimento aleatorio} es aquel en el que se conoce cuál es el conjunto de resultados
posibles antes de su realización pero se desconoce cuál será el resultado concreto del mismo.
\end{definicion}

Un ejemplo sencillo de experimentos aleatorios son los juegos de azar. Por ejemplo, el lanzamiento de un dado es un experimento aleatorio ya
que:
\begin{itemize}
\item Se conoce el conjunto posibles de resultados $\{1,2,3,4,5,6\}$.
\item Antes de lanzar el dado, es imposible predecir con absoluta certeza el valor que saldrá. 
\end{itemize}

A lo largo del tema utilizaremos varias veces los juegos de azar para dar ejemplos sencillos que ayuden a comprender los conceptos de la
teoría de la probabilidad, pero también daremos ejemplos más aplicacos a las ciencias de la salud. 

Otro ejemplo de experimento aleatorio más aplicado a la salud sería la selección de un individuo de una población al azar y la determinación
de su grupo sanguíneo. En este caso el conjunto de posibles resultados serían los cuatro grupos sanguíneos A, B, 0 y AB. De nuevo antes de
seleccionar la individuo es imposible predecir con absoluta certeza cuál será el grupo sanguíneo resultante. 

En general, la obtención de cualquier muestra mediante procedimientos aleatorios será un experimento aleatorio.  
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Espacio muestral}
\begin{definicion}[Espacio muestral]
Al conjunto $E$ de todos los posibles resultados de un experimento aleatorio se le llama \emph{espacio muestral}.
\end{definicion}

Algunos ejemplos de espacios muestrales son:
\begin{itemize}
\item Lanzamiento de una moneda: $E=\{c,x\}$.
\item Lanzamiento de un dado: $E=\{1,2,3,4,5,6\}$.
\item Grupo sanguíneo de un individuo seleccionado al azar: $E=\{\mbox{A},\mbox{B},\mbox{AB},\mbox{0}\}$.
\item Estatura de un individuo seleccionado al azar: $\mathbb{R}^+$.
\end{itemize}

\note{Al conjunto $E$ de todos los posibles resultados de un experimento aleatorio se le llama \emph{espacio muestral}.
\end{definicion}

Algunos ejemplos de espacios muestrales son:
\begin{itemize}
\item Lanzamiento de una moneda: $E=\{c,x\}$.
\item Lanzamiento de un dado: $E=\{1,2,3,4,5,6\}$.
\item Grupo sanguíneo de un individuo seleccionado al azar: $E=\{\mbox{A},\mbox{B},\mbox{AB},\mbox{0}\}$.
\item Estatura de un individuo seleccionado al azar: $\mathbb{R}^+$. En este último caso se trataría de un conjunto con infinitos valores. 
\end{itemize}
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Construcción del espacio muestral}
En los experimentos donde se miden más de una variable, la construcción del espacio muestral puede complicarse. En tales casos, es
recomendable utilizar un \structure{\textbf{diagrama de árbol}} de manera que cada nivel del árbol es una variable observada y cada rama un
posible valor.

Por ejemplo, si el experimento consiste en observar el sexo y el grupo sanguíneo de una persona, el espacio muestral podría construirse
mediante el siguiente árbol:

\begin{center}
\psset{treesep=0.2cm, levelsep=2cm}
\renewcommand{\psedge}[2]{\ncdiag[armA=0.7cm,angleA=180,angleB=0,armB=0cm]{#2}{#1}} 
\pstree[treemode=R, nodesep=1pt]{\Tp*}{
	\pstree[linestyle=none]{\TR[edge=none]{Sexo}}{\pstree{\TR{Grupo}}{\TR{$E$}}}
	\pstree{\TR{Mujer}}{
		\pstree[linestyle=none]{\TR{A}}{\TR{(Mujer,A)}}
		\pstree[linestyle=none]{\TR{B}}{\TR{(Mujer,B)}}
		\pstree[linestyle=none]{\TR{AB}}{\TR{(Mujer,AB)}}
		\pstree[linestyle=none]{\TR{0}}{\TR{(Mujer,0)}}
	}
	\pstree{\TR{Hombre}}{
		\pstree[linestyle=none]{\TR{A}}{\TR{(Hombre,A)}}
		\pstree[linestyle=none]{\TR{B}}{\TR{(Hombre,B)}}
		\pstree[linestyle=none]{\TR{AB}}{\TR{(Hombre,AB)}}
		\pstree[linestyle=none]{\TR{0}}{\TR{(Hombre,0)}}
	}
	\pstree[linestyle=none]{\Tp[edge=none]}{\Tp}
}
\end{center}

\note{
Lo primero que hay que conocer de un experimento aleatorio es su espacio muestral.

En los experimentos donde se miden más de una variable, la construcción del espacio muestral puede complicarse. En tales casos, es
recomendable utilizar un \structure{\textbf{diagrama de árbol}}. En este diagrama, se representa un árbol con distintos niveles de
ramificación, donde cada nivel del árbol corresponde a una variable observada y cada rama a un posible valor de la variable.

Por ejemplo, si el experimento consiste en observar el sexo y el grupo sanguíneo de una persona, el espacio muestral podría construirse
mediante el siguiente árbol:
\begin{center}
\psset{treesep=0.2cm, levelsep=2cm}
\renewcommand{\psedge}[2]{\ncdiag[armA=0.7cm,angleA=180,angleB=0,armB=0cm]{#2}{#1}} 
\pstree[treemode=R, nodesep=1pt]{\Tp*}{
	\pstree[linestyle=none]{\TR[edge=none]{Sexo}}{\pstree{\TR{Grupo}}{\TR{$E$}}}
	\pstree{\TR{Mujer}}{
		\pstree[linestyle=none]{\TR{A}}{\TR{(Mujer,A)}}
		\pstree[linestyle=none]{\TR{B}}{\TR{(Mujer,B)}}
		\pstree[linestyle=none]{\TR{AB}}{\TR{(Mujer,AB)}}
		\pstree[linestyle=none]{\TR{0}}{\TR{(Mujer,0)}}
	}
	\pstree{\TR{Hombre}}{
		\pstree[linestyle=none]{\TR{A}}{\TR{(Hombre,A)}}
		\pstree[linestyle=none]{\TR{B}}{\TR{(Hombre,B)}}
		\pstree[linestyle=none]{\TR{AB}}{\TR{(Hombre,AB)}}
		\pstree[linestyle=none]{\TR{0}}{\TR{(Hombre,0)}}
	}
	\pstree[linestyle=none]{\Tp[edge=none]}{\Tp}
}
\end{center}
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Sucesos aleatorios}
\begin{definicion}[Suceso aleatorio]
Un \emph{suceso aleatorio} es cualquier subconjunto del espacio muestral $E$ de un experimento aleatorio. 
\end{definicion}

Existen distintos tipos de sucesos:
\begin{description}
\item[Suceso imposible:] Es el subconjunto vacío $\emptyset$. El suceso nunca ocurre.
\item[Sucesos elementales:] Son los subconjuntos formados por un solo elemento. 
\item[Sucesos compuestos:] Son los subconjuntos formados por dos o más elementos.
\item[Suceso seguro:] Es el propio espacio muestral. El suceso seguro siempre ocurre.
\end{description}

\note{
\begin{definicion}
Un \emph{suceso aleatorio} es cualquier subconjunto del espacio muestral $E$ de un experimento aleatorio. 
\end{definicion}

Existen distintos tipos de sucesos:
\begin{description}
\item[Suceso imposible:] Es el subconjunto vacío $\emptyset$. El suceso nunca ocurre. Se llama imposible porque al realizar el experimento,
no se sabe qué ocurrirá pero es imposible que no ocurra nada. 
\item[Sucesos elementales:] Son los subconjuntos formados por un solo elemento. Hay tantos sucesos elementales como elementos tenga el
espacio muestral.
\item[Sucesos compuestos:] Son los subconjuntos formados por dos o más elementos.
\item[Suceso seguro:] Es el propio espacio muestral. Se llama suceso seguro porque al realizar el experimento siempre ocurrirá algo del
espacio muestral. 
\end{description}
}
\end{frame}


\subsection{Teoría de conjuntos}

%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Espacio de sucesos}
\begin{definicion}[Espacio de sucesos] Dado un espacio muestral $E$ de un
experimento aleatorio, el conjunto formado por todos los posibles sucesos de $E$ se llama \emph{espacio de sucesos de $E$} y se denota
$\mathcal{P}(E)$.
\end{definicion}

Ejemplo. Dado el espacio muestral $E=\{a,b,c\}$, se tiene 
\[
\mathcal{P}(E)=\left\{\emptyset, \{a\},\{b\},\{c\},\{a,b\},\{a,c\},\{b,c\},\{a,b,c\}\right\}
\]

\note{
\begin{definicion}[Espacio de sucesos] Dado un espacio muestral $E$ de un
experimento aleatorio, el conjunto formado por todos los posibles sucesos de $E$ se llama \emph{espacio de sucesos de $E$} y se denota
$\mathcal{P}(E)$, también conocido como partes de $E$.
\end{definicion}

Ejemplo. Dado el espacio muestral $E=\{a,b,c\}$, se tiene 
\[
\mathcal{P}(E)=\left\{\emptyset, \{a\},\{b\},\{c\},\{a,b\},\{a,c\},\{b,c\},\{a,b,c\}\right\}
\]
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Operaciones entre sucesos}
Puesto que los sucesos son conjuntos, por medio de la teoría de conjuntos se pueden definir las siguientes operaciones entre sucesos:
\begin{itemize}
\item Unión.
\item Intersección.
\item Complementario.
\item Diferencia.
\end{itemize}

\note{
Puesto que los sucesos son conjuntos, tiene sentido definir operaciones entre sucesos a partir de la teoría de conjuntos. Las operaciones
más habituales que se verán son: 
\begin{itemize}
\item Unión.
\item Intersección.
\item Complementario.
\item Diferencia.
\end{itemize}
}
\end{frame}


% ---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Unión de sucesos}
\begin{definicion}[Suceso unión]
Dados dos sucesos $A,B\in \mathcal{P}(E)$, se llama \emph{suceso unión} de $A$ y $B$, y se denota $A\cup B$, al suceso formado por los
elementos de $A$ junto a los elementos de $B$, es decir,
\[
A\cup B = \{x\,|\, x\in A\textrm{ o }x\in B\}.
\]
\begin{center}
\psset{unit=0.8}
\begin{pspicture}(-1,-1.5)(4,1.5)
\psset{fillstyle=solid}
\pscustom[fillcolor=white]{
\psframe(-1,-1.5)(4,1.5)}
\pscustom[fillcolor=yellow]{%
\psarc(1,0){1}{60}{-60}
\psarcn(2,0){1}{240}{120}}
\pscustom[fillcolor=yellow]{%
\psarc(2,0){1}{240}{120}
\psarcn(1,0){1}{60}{-60}}
\pscustom[fillcolor=yellow]{%
\psarc(1,0){1}{-60}{60}
\psarc(2,0){1}{120}{240}}
\rput(-0.7,1.2){$E$}
\rput(0.5,0){$A$}
\rput(1.5,-1.2){$A\cup B$}
\rput(2.5,0){$B$}
\end{pspicture}
\end{center}
\end{definicion}

El suceso unión $A\cup B$ ocurre siempre que ocurre $A$ \alert{o} $B$.

Ejemplo. Sea $E=\{1,2,3,4,5,6\}$, el conjunto de los números de un dado, y $A=\{2,4,6\}$ y $B=\{1,2,3,4\}$. Entonces $A\cup
B=\{1,2,3,4,6\}$.

\note{
\begin{definicion}[Suceso unión]
Dados dos sucesos $A,B\in \mathcal{P}(E)$, se llama \emph{suceso unión} de $A$ y $B$, y se denota $A\cup B$, al suceso formado por los
elementos de $A$ junto a los elementos de $B$, es decir,
\[
A\cup B = \{x\,|\, x\in A\textrm{ o }x\in B\}.
\]
\end{definicion}

El suceso unión $A\cup B$ ocurre siempre que ocurre $A$ \alert{o} $B$ y por tanto está asociado al nexo o del castellano.

Ejemplo. Sea $E=\{1,2,3,4,5,6\}$, el conjunto de los números de un dado, y $A=\{2,4,6\}$ y $B=\{1,2,3,4\}$. Entonces $A\cup
B=\{1,2,3,4,6\}$.
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Intersección de sucesos}
\begin{definicion}[Suceso intersección]
Dados dos sucesos $A,B\in \mathcal{P}(E)$, se llama \emph{suceso intersección} de $A$ y $B$, y se denota $A\cap B$, al suceso formado por los elementos comunes de $A$ y $B$, es decir,
\[
A\cap B = \{x\,|\, x\in A\textrm{ y }x\in B\}.
\]
\begin{center}
\psset{unit=0.8}
\begin{pspicture}(-1,-1.5)(4,1.5)
\psset{fillstyle=solid}
\pscustom[fillcolor=white]{\psframe(-1,-1.5)(4,1.5)}
\pscustom[fillstyle=none]{%
\psarc(1,0){1}{60}{-60}
\psarcn(2,0){1}{240}{120}}
\pscustom[fillstyle=none]{%
\psarc(2,0){1}{240}{120}
\psarcn(1,0){1}{60}{-60}}
\pscustom[fillcolor=yellow]{%
\psarc(1,0){1}{-60}{60}
\psarc(2,0){1}{120}{240}}
\rput(-0.7,1.2){$E$}
\rput(0.5,0){$A$}
\rput(1.5,-1.2){$A\cap B$}
\rput(2.5,0){$B$}
\end{pspicture}
\end{center}
\end{definicion}

El suceso intersección $A\cap B$ ocurre siempre que ocurren $A$ \alert{y} $B$.

Ejemplo. Sea $E=\{1,2,3,4,5,6\}$, el conjunto de los números de un dado, y
$A=\{2,4,6\}$ y $B=\{1,2,3,4\}$. Entonces $A\cap B=\{2,4\}$.

Diremos que dos sucesos son \structure{\textbf{incompatibles}} si su intersección es vacía.
Por ejemplo $A=\{2,4,6\}$ y $C=\{1,3\}$ son incompatibles.

\note{
\begin{definicion}[Suceso intersección]
Dados dos sucesos $A,B\in \mathcal{P}(E)$, se llama \emph{suceso intersección} de $A$ y $B$, y se denota $A\cap B$, al suceso formado por los elementos comunes de $A$ y $B$, es decir,
\[
A\cap B = \{x\,|\, x\in A\textrm{ y }x\in B\}.
\]
\end{definicion}

El suceso intersección $A\cap B$ ocurre siempre que ocurren $A$ \alert{y} $B$, y por tanto está asociado al nexo y del castellano.

Ejemplo. Sea $E=\{1,2,3,4,5,6\}$, el conjunto de los números de un dado, y
$A=\{2,4,6\}$ y $B=\{1,2,3,4\}$. Entonces $A\cap B=\{2,4\}$.

Diremos que dos sucesos son \structure{\textbf{incompatibles}} cuando no tienen nada en común, es decir, si su intersección es vacía.
Por ejemplo $A=\{2,4,6\}$ y $C=\{1,3\}$ son incompatibles. Dos sucesos incompatibles nunca pueden ocurrir a la vez. 
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Contrario de un suceso}
\begin{definicion}[Suceso contrario]
Dado un conjunto $A\in \mathcal{P}(E)$, se llama \emph{suceso contrario o complementario} de $A$, y se denota $\bar A$, al suceso formado por los elementos de $E$ que no pertenecen a $A$, es decir,
\[
\overline A = \{x\,|\, x\not\in A\}.
\]
\begin{center}
\psset{unit=0.8}
\begin{pspicture}(-1,-1.5)(4,1.5)
\psset{fillstyle=solid}
\pscustom[fillcolor=yellow]{
\psframe(-1,-1.5)(4,1.5)}
\pscustom[fillcolor=white]{%
\psarc(1,0){1}{0}{360}}
\rput(-0.7,1.2){$E$}
\rput(1,0){$A$}
\rput(3,0){$\overline A$}
\end{pspicture}
\end{center}
\end{definicion}

El suceso contrario $\bar A$ ocurre siempre que \alert{no} ocurre $A$.

Ejemplo. Sea $E=\{1,2,3,4,5,6\}$, el conjunto de los números de un dado, y
$A=\{2,4,6\}$. Entonces $\overline A=\{1,3,5\}$.

\note{
\begin{definicion}[Suceso contrario]
Dado un conjunto $A\in \mathcal{P}(E)$, se llama \emph{suceso contrario o complementario} de $A$, y se denota $\bar A$, al suceso formado por los elementos de $E$ que no pertenecen a $A$, es decir,
\[
\overline A = \{x\,|\, x\not\in A\}.
\]
\end{definicion}

El suceso contrario $\bar A$ ocurre siempre que \alert{no} ocurre $A$, y por tanto esta ligado a la negación en castellano. 

Ejemplo. Sea $E=\{1,2,3,4,5,6\}$, el conjunto de los números de un dado, y
$A=\{2,4,6\}$. Entonces $\overline A=\{1,3,5\}$.
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Diferencia de sucesos}
\begin{definicion}[Suceso diferencia]
Dados dos sucesos $A,B\in \mathcal{P}(E)$, se llama \emph{suceso diferencia} de $A$ y $B$, y se denota $A-B$, al suceso formado por los elementos de $A$ que no pertenecen a $B$, es decir,
\[
A-B = \{x\,|\, x\in A\textrm{ y }x\not\in B\}.
\]
\begin{center}
\psset{unit=0.8}
\begin{pspicture}(-1,-1.5)(4,1.5)
\psset{fillstyle=solid}
\pscustom[fillcolor=white]{
\psframe(-1,-1.5)(4,1.5)}
\pscustom[fillcolor=yellow]{%
\psarc(1,0){1}{60}{-60}
\psarcn(2,0){1}{240}{120}}
\pscustom[fillstyle=none]{%
\psarc(2,0){1}{240}{120}
\psarcn(1,0){1}{60}{-60}}
\pscustom[fillstyle=none]{%
\psarc(1,0){1}{-60}{60}
\psarc(2,0){1}{120}{240}}
\rput(-0.7,1.2){$E$}
\rput(0.5,0){$A$}
\rput(1.5,-1.2){$A-B$}
\rput(2.5,0){$B$}
\end{pspicture}
\end{center}
\end{definicion}

El suceso diferencia $A-B$ ocurre siempre que ocurre $A$ pero no ocurre $B$, y también puede expresarse como $A\cap \bar B$.

Ejemplo. Sea $E=\{1,2,3,4,5,6\}$, el conjunto de los números de un dado, y
$A=\{2,4,6\}$ y $B=\{1,2,3,4\}$. Entonces $A-B=\{6\}$ y $B-A=\{1,3\}$.

\note{
\begin{definicion}[Suceso diferencia]
Dados dos sucesos $A,B\in \mathcal{P}(E)$, se llama \emph{suceso diferencia} de $A$ y $B$, y se denota $A-B$, al suceso formado por los elementos de $A$ que no pertenecen a $B$, es decir,
\[
A-B = \{x\,|\, x\in A\textrm{ y }x\not\in B\}.
\]
\end{definicion}

El suceso diferencia $A-B$ ocurre siempre que ocurre $A$ pero no ocurre $B$, y también puede expresarse como $A\cap \bar B$.

Ejemplo. Sea $E=\{1,2,3,4,5,6\}$, el conjunto de los números de un dado, y
$A=\{2,4,6\}$ y $B=\{1,2,3,4\}$. Entonces $A-B=\{6\}$.
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Álgebra de sucesos}
Dados los sucesos $A,B,C\in  \mathcal{P}(E)$, se cumplen las siguientes propiedades:
\begin{enumerate}
\item $A\cup A=A$, $A\cap A=A$ (idempotencia).
\item $A\cup B=B\cup A$, $A\cap B = B\cap A$ (conmutativa).
\item $(A\cup B)\cup C = A\cup (B\cup C)$, $(A\cap B)\cap C = A\cap (B\cap C)$ (asociativa).
\item $(A\cup B)\cap C = (A\cap C)\cup (B\cap C)$, $(A\cap B)\cup C = (A\cup C)\cap (B\cup C)$ (distributiva).
\item $A\cup \emptyset=A$, $A\cap E=A$ (elemento neutro).
\item $A\cup E=E$, $A\cap \emptyset=\emptyset$ (elemento absorbente).
\item $A\cup \overline A = E$, $A\cap \overline A= \emptyset$ (elemento simétrico complementario).
\item $\overline{\overline A} = A$ (doble contrario).
\item $\overline{A\cup B} = \overline A\cap \overline B$, $\overline{A\cap B} = \overline A\cup \overline B$ (leyes de Morgan).
\item $A\cap B\subseteq A\cup B$.
\end{enumerate}

\note{
Las operaciones entre sucesos vistas cumplen toda una serie de propiedades que no demostraremos aunque algunas de ellas son fáciles de
comprobar:
\begin{enumerate}
\item $A\cup A=A$, $A\cap A=A$ (idempotencia).
\item $A\cup B=B\cup A$, $A\cap B = B\cap A$ (conmutativa).
\item $(A\cup B)\cup C = A\cup (B\cup C)$, $(A\cap B)\cap C = A\cap (B\cap C)$ (asociativa).
\item $(A\cup B)\cap C = (A\cap C)\cup (B\cap C)$, $(A\cap B)\cup C = (A\cup C)\cap (B\cup C)$ (distributiva).
\item $A\cup \emptyset=A$, $A\cap E=A$ (elemento neutro).
\item $A\cup E=E$, $A\cap \emptyset=\emptyset$ (elemento absorbente).
\item $A\cup \overline A = E$, $A\cap \overline A= \emptyset$ (elemento simétrico complementario).
\item $\overline{\overline A} = A$ (doble contrario).
\item $\overline{A\cup B} = \overline A\cap \overline B$, $\overline{A\cap B} = \overline A\cup \overline B$ (leyes de Morgan).
\item $A\cap B\subseteq A\cup B$.
\end{enumerate} 
}
\end{frame}


\subsection{Definición de probabilidad}

%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Definición clásica de probabilidad}
\begin{definicion}[Probabilidad Clásica de Laplace]
Para un experimento aleatorio donde todos los elementos del espacio muestral $E$ son equiprobables, se define la \emph{probabilidad} de un
suceso $A\subseteq E $ como el cociente entre el número de elementos de $A$ y el número de elementos de $E$:
\[ P(A) = \frac{|A|}{|E|} = \frac{\mbox{nº casos favorables a A}}{\mbox{nº casos posibles}}\]
\end{definicion}

Esta definición es ampliamente utilizada, aunque tiene importantes restricciones:
\begin{itemize}
\item No puede utilizarse con espacios muestrales infinitos, o de los que no se conoce el número de casos posibles.
\item Es necesario que todos los elementos del espacio muestral tengan la misma probabilidad de ocurrir (\emph{equiprobabilidad}).  
\end{itemize}

\alert{\emph{¡Ojo! Esto no se cumple en muchos experimentos aleatorios reales.}}

\note{
Como hemos visto, en u experimento aleatorio, un determinado suceso puede ocurrir o no al realizar el experimento, es decir, existe cierta
incertidumbre sobre su ocurrencia. Tiene sentido, por tanto, cuantificar dicha incertidumbre y medir así la verosimilitud del suceso o la
confianza que se tiene en que ocurra, y esto es lo que trata de hacer la probabilidad.

La definición clásica de probabilidad se debe al matemático francés Laplace y define la probabilidad de un suceso como un cociente entre el
número de elementos del suceso y el número de elementos del espacio muestral del experimento aleatorio, más conocida como casos favorables
al suceso entre casos posibles del espacio muestral.

Esta definición es ampliamente utilizada, aunque tiene importantes restricciones:
\begin{itemize}
\item No puede utilizarse con espacios muestrales infinitos, o de los que no se conoce el número de casos posibles.
\item Es necesario que todos los elementos del espacio muestral tengan la misma probabilidad de ocurrir (\emph{equiprobabilidad}).  
\end{itemize}
Aunque esto suele cumplirse en los juegos de azar, en otros muchos experimentos no es cierto. Por ejemplo los grupos sanguíneos no son
equiprobables ya que hay mucha más gente con el grupo $A$ que con otro grupo. 
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Definición frecuentista de probabilidad}
\begin{teorema}[Ley de los grandes números]
Cuando un experimento aleatorio se repite un gran número de veces, las frecuencias relativas de los sucesos del
experimento tienden a estabilizarse en torno a cierto número, que es precisamente su probabilidad.
\end{teorema}

De acuerdo al teorema anterior, podemos dar la siguiente definición
\begin{definicion}[Probabilidad frecuentista]
Para un experimento aleatorio reproducible, se define la \emph{probabilidad} de un suceso $A\subseteq E $ como la frecuencia relativa del
suceso $A$ en infinitas repeticiones del experimento:
\[ P(A) = lim_{n\rightarrow \infty}\frac{n_{A}}{n}\]
\end{definicion}

Aunque esta definición es muy útil en experimentos científicos reproducibles, también tiene serios inconvenientes, ya que
\begin{itemize}
\item Sólo se calcula una aproximación de la probabilidad real.
\item La repetición del experimento debe ser en las mismas condiciones.  
\end{itemize}

\note{
Otra definición común de probabilidad surge de la ley de los grandes números que dice que 
cuando un experimento aleatorio se repite un gran número de veces, las frecuencias relativas de los sucesos del
experimento tienden a estabilizarse en torno a cierto número, que es precisamente su probabilidad.

Un ejemplo que demuestra el cumplimiento de esta ley puede realizarse tirando múltiples veces una moneda y anotando la frecuencia relativa
de caras. A medida que se tire más veces la moneda se verá que la frecuencia relativa de caras se va estabilizando en torno a $0.5$ que es
la probabilidad de sacar cara. 

Para un experimento aleatorio reproducible, se puede definir así la probabilidad de un suceso como el límite cuando el número de
repeticiones del mismo tiende a infinito de la frecuencia relativa del suceso.

Esta definición permitiría calcular de manera aproximada la probabilidad de que una persona elegida al azar tenga grupo sanguíneo $A$
simplemente tomando una muestra grande de la población y calculando la frecuencia relativa de personas con el grupo $A$ en la muestra.
Cuanto mayor sea la muestra, mejor será la aproximación de la verdadera probabilidad del grupo $A$.

Aunque esta definición es muy útil en experimentos científicos reproducibles, también tiene serios inconvenientes, ya que
\begin{itemize}
\item Sólo se calcula una aproximación de la probabilidad real.
\item La repetición del experimento debe ser en las mismas condiciones.  
\end{itemize}
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Definición axiomática de probabilidad}
\begin{definicion}[Kolmogórov]
Se llama \emph{probabilidad} a toda aplicación que asocia a cada suceso $A$ del espacio de sucesos de un experimento aleatorio, un número
real $P(A)$, que cumple los siguientes axiomas:
\begin{enumerate}
\item La probabilidad de un suceso cualquiera es positiva o nula: \[P(A)\geq 0.\]
\item La probabilidad de la unión de dos sucesos incompatibles es igual a la suma de las probabilidades de cada uno de ellos:       
\[P(A\cup B) = P(A)+P(B).\]
\item La probabilidad del suceso seguro es igual a la unidad: 
\[P(E)=1.\]
\end{enumerate}
\end{definicion}

\note{
La definición de probabilidad más aceptada actualmente es la definición axiomática de Kolmogorov, quien definió la probabilidad como 
una medida de verosimilitud que asocia a cada suceso de un experimento aleatorio un número real, conocido como probabilidad del suceso, y
que cumple tres axiomas:
\begin{enumerate}
\item La probabilidad de un suceso cualquiera es positiva o nula: \[P(A)\geq 0.\]
\item La probabilidad de la unión de dos sucesos incompatibles es igual a la suma de las probabilidades de cada uno de ellos:       
\[P(A\cup B) = P(A)+P(B).\]
\item La probabilidad del suceso seguro es igual a la unidad: 
\[P(E)=1.\]
\end{enumerate}

Estos axiomas los cumplen todas las definiciones históricas de probabilidad y por tanto, todas ellas tienen cabida bajo la definición
axiomática de Kolmogorov.
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Consecuencias de los axiomas de probabilidad}
A partir de los axiomas de la definición de probabilidad se pueden deducir los siguientes resultados:
\begin{enumerate}
\item <2-> $P(\bar A) = 1-P(A)$.
\item <3->$P(\emptyset)= 0$.
\item <4->Si $A\subseteq B$ entonces $P(A)\leq P(B)$.
\item <5->$P(A) \leq 1$.
\item <6->Si $A$ y $B$ son sucesos compatibles, es decir, su intersección no es vacía, entonces 
\[P(A\cup B)= P(A) + P(B) - P(A\cap B).\]
\item <7->Si el suceso $A$ está compuesto por los sucesos elementales $e_1,e_2,...,e_n$, entonces
\[P(A)=\sum_{i=1}^n P(e_i).\]
\end{enumerate}

\mode<presentation>{
\begin{center}
\psset{unit=0.8}
\begin{pspicture}(0,-1)(0,0)
\uncover<2>{
\rput[c](0,0){$A \cup \bar A = E \Leftrightarrow P(A\cup \bar A) = P(E) \Leftrightarrow P(A)+P(\bar A) = 1.$}
}
\uncover<3>{
\rput[c](0,0){$\emptyset = \bar E \Leftrightarrow P(\emptyset) = P(\bar E) = 1-P(E) = 1-1 = 0.$}
}
\uncover<4>{
\rput[c](0,0){$B = A\cup (B-A) \Leftrightarrow P(B) = P(A\cup (B-A) = P(A)+P(B-A) \geq P(A).$}
}
\uncover<5>{
\rput[c](0,0){$A\subseteq E \Leftrightarrow P(A)\leq P(E)=1.$}
}
\uncover<6>{
\psset{fillstyle=solid}
\pscustom[fillcolor=yellow]{%
\psarc(-0.5,1){1}{60}{-60}
\psarcn(0.5,1){1}{240}{120}}
\pscustom[fillcolor=yellow]{%
\psarc(0.5,1){1}{240}{120}
\psarcn(-0.5,1){1}{60}{-60}}
\pscustom[fillcolor=yellow]{%
\psarc(-0.5,1){1}{-60}{60}
\psarc(0.5,1){1}{120}{240}}
\rput(-0.75,1){$A$}
\rput(0,-0.5){$A\cup B$}
\rput(0.75,1){$B$}
}
\uncover<7>{
\rput[c](0,0){$A=\{e_1,\cdots,e_n\} = \{e_1\}\cup \cdots \cup \{e_n\} \Leftrightarrow 
P(A)=P(\{e_1\}\cup \cdots \cup \{e_n\}) = P(\{e_1\})+ \cdots P(\{e_n\}). $} 
}
\end{pspicture}
\end{center}
}

\note{
A partir de los axiomas de la definición de probabilidad se pueden deducir las siguientes propiedades.
\begin{enumerate}
\item $P(\bar A) = 1-P(A)$.
\item $P(\emptyset)= 0$.
\item Si $A\subseteq B$ entonces $P(A)\leq P(B)$.
\item $P(A) \leq 1$. Esto sumado al primer axioma restringe el valor de la probabilidad al intervalo real $[0,1]$.
\item Si $A$ y $B$ son sucesos compatibles, es decir, su intersección no es vacía, entonces 
\[P(A\cup B)= P(A) + P(B) - P(A\cap B).\]
Esta es la fórmula que utilizaremos habitualmente para calcular la probabilidad de una unión pues también funciona para sucesos
incompatibles ya que en tal caso la intersección sería el suceso vacío y su probabilidad ya hemos visto que es nula. 
\item Si el suceso $A$ está compuesto por los sucesos elementales $e_1,e_2,...,e_n$, entonces
\[P(A)=\sum_{i=1}^n P(e_i).\]
Esta propiedad es muy interesante ya que si conocemos las probabilidades de todos los elementos del espacio muestral podremos calcular la
probabilidad de cualquier suceso simplemente sumando las probabilidades de los elementos que lo componenen. 
\end{enumerate}
}
\end{frame}


\subsection{Probabilidad condicionada}

%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Experimentos condicionados}
En algunas ocasiones puede que haya que calcular la probabilidad de algún suceso $A$ sabiendo que ha ocurrido otro $B$. En tal caso se dice
que el suceso $B$ es un \emph{condicionante}, y la probabilidad del suceso condicionado suele escribirse como 
\[P(A/B).\]

Los condicionantes, en el fondo, cambian el espacio muestral del experimento y por tanto las probabilidades de sus sucesos.

\textbf{Ejemplo}. Supongamos que hemos observado las siguientes frecuencias de aprobados en un grupo de 100 hombres y 100 mujeres:
\[
\begin{array}{|c|c|c|}
\cline{2-3}
 \multicolumn{1}{c|}{} & \mbox{Aprobados} & \mbox{Suspensos} \\ \hline 
 \rowcolor{coral} \mbox{Mujeres} & 80 & 20 \\ \hline
 \mbox{Hombres} & 60 & 40 \\ \hline
\end{array}
\]
Entonces, la probabilidad de que una persona elegida al azar haya aprobado es $P(\mbox{Aprobado})= 140/200=0.7$.

Sin embargo, si se sabe que la persona elegida es mujer, entonces se tiene $P(\mbox{Aprobado}/\mbox{Mujer})=80/100=0.8$.

\note{
La incertidumbre sobre un suceso depende de la información que se tenga sobre el experimento aleatorio. 
En algunas ocasiones puede que haya que calcular la probabilidad de algún suceso $A$ sabiendo que ha ocurrido otro $B$. En tal caso se dice
que el suceso $B$ es un \emph{condicionante}, y la probabilidad del suceso condicionado suele escribirse como \[P(A/B)\]

Los condicionantes, en el fondo, cambian el espacio muestral del experimento y por tanto las probabilidades de sus sucesos.

\textbf{Ejemplo}. Supongamos que hemos observado las siguientes frecuencias de aprobados en un grupo de 100 hombres y 100 mujeres:
\[
\begin{array}{|c|c|c|}
\cline{2-3}
 \multicolumn{1}{c|}{} & \mbox{Aprobados} & \mbox{Suspensos} \\ \hline 
 \rowcolor{coral} \mbox{Mujeres} & 80 & 20 \\ \hline
 \mbox{Hombres} & 60 & 40 \\ \hline
\end{array}
\]
Entonces, utilizando la definición de frecuentista, la probabilidad de que una persona elegida al azar haya aprobado es
la frecuencia relativa de aprobados que es$P(\mbox{Aprobado})= 140/200=0.7$.

Sin embargo, si se añade información sobre el experimento y nos dicen que la persona elegida es mujer, entonces la muestra se restringiría
sólo a las mujeres y la frecuencia relativa de aprobados en mujeres es $P(\mbox{Aprobado}/\mbox{Mujer})=80/100=0.8$. 
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Probabilidad condicionada}
\begin{definicion}[Probabilidad condicionada]
Dados dos sucesos $A$ y $B$ de un mismo espacio de sucesos de un experimento aleatorio, la probabilidad de $A$
\emph{condicionada} por $B$ es \[ P(A/B) = \frac{P(A\cap B)}{P(B)},\]
siempre y cuando, $P(B)\neq 0$.
\end{definicion}

Esta definición permite calcular probabilidades sin tener que alterar el espacio muestral original del experimento.

\textbf{Ejemplo}. En el ejemplo anterior se tiene que la probabilidad del suceso Aprobado condicionada por el suceso
Mujer es \[P(\mbox{Aprobado}/\mbox{Mujer})= \frac{P(\mbox{Aprobado}\cap \mbox{Mujer})}{P(\mbox{Mujer})} = \frac{80/200}{100/200}=\frac{80}{100}=0.8.\]

De esta definición se deduce que la probabilidad de la intersección es
\[ P(A\cap B) = P(A)P(B/A) = P(B)P(A/B).\]

\note{
El problema de los condicionamientos es que suelen cambiar el espacio muestral de partida. Afortunadamente, es posible calcular
probabilidades condicionadas sin cambiar de espacio muestral gracias a la siguiente fórmula.

\begin{definicion}[Probabilidad condicionada]
Dados dos sucesos $A$ y $B$ de un mismo espacio de sucesos de un experimento aleatorio, la probabilidad de $A$
\emph{condicionada} por $B$ es 
\[ P(A/B) = \frac{P(A\cap B)}{P(B)},\]
siempre y cuando, $P(B)\neq 0$.
\end{definicion}

\textbf{Ejemplo}. En el ejemplo anterior se tiene que la probabilidad del suceso Aprobado condicionada por el suceso
Mujer es \[P(\mbox{Aprobado}/\mbox{Mujer})= \frac{P(\mbox{Aprobado}\cap \mbox{Mujer})}{P(\mbox{Mujer})} = \frac{80/200}{100/200}=\frac{80}{100}=0.8.\]

Por otro lado, de esta definición se deduce también que la probabilidad de la intersección de dos sucesos puede calcularse multiplicando la
probabilidad de uno de ellos por la probabilidad del otro condicionado por el primero, es decir, 
\[ P(A\cap B) = P(A)P(B/A) = P(B)P(A/B).\]

Esta será la fórmula que utilizaremos habitualmente para calcular la probabilidad de la intersección de sucesos. 
}
\end{frame}


\subsection{Dependencia e independencia de sucesos}

%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Independencia de sucesos}
\begin{definicion}[Sucesos independientes]
Dados dos sucesos $A$ y $B$ de un mismo espacio de sucesos de un experimento aleatorio, se dice que $A$ es \emph{independiente} de $B$, si
la probabilidad de $A$ no se ve alterada al condicionar por $B$, es decir,
\[ P(A/B) = P(A).\]
\end{definicion}

Si $A$ es independiente de $B$, también se cumple que $B$ es independiente de $A$, y en general simplemente se dice que $A$ y $B$ son
independientes.

También se cumple que si $A$ y $B$ son independientes, entonces 
\[ P(A\cap B) = P(A)P(B). \]

\note{
En ocasiones, saber que un determinado suceso ha ocurrido no cambia la incertidumbre sobre otro suceso del mismo experimento. Por ejemplo,
si se tiran dos monedas, está claro que el resultado de la primera no cambia la incertidumbre sobre que salga cara en la segunda. En tal
caso se dice que los sucesos son independientes.

Formalmente,
\begin{definicion}[Sucesos independientes]
Dados dos sucesos $A$ y $B$ de un mismo espacio de sucesos de un experimento aleatorio, se dice que $A$ es \emph{independiente} de $B$, si
la probabilidad de $A$ no se ve alterada al condicionar por $B$, es decir,
\[ P(A/B) = P(A).\]
\end{definicion}

Si $A$ es independiente de $B$, también se cumple que $B$ es independiente de $A$, y en general simplemente se dice que $A$ y $B$ son
independientes.

También se cumple que si $A$ y $B$ son independientes, entonces 
\[ P(A\cap B) = P(A)P(B/A) = P(A)P(B). \]
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Espacios probabilísticos}
Ya se vio que en experimentos donde se medía más de una variable, era conveniente construir el espacio muestral
mediante un diagrama de árbol.

Dicho diagrama también es útil para calcular las probabilidades de cada uno de los elementos del espacio muestral del siguiente modo:
\begin{enumerate}
\item Para cada nodo del árbol, etiquetar su rama con la probabilidad de que la variable correspondiente tome el valor del nodo, condicionada por la ocurrencia de todos los nodos que conducen hasta el actual.
\item La probabilidad de cada suceso elemental se calcula multiplicando las probabilidades que etiquetan las ramas que
conducen hasta él.
\end{enumerate}
\begin{center}
\scalebox{0.9}{
\psset{treesep=0.6cm, levelsep=2cm, tpos=0.6}
\renewcommand{\psedge}[2]{\ncdiag[armA=1cm,angleA=180,angleB=0,armB=0cm]{#2}{#1}} 
\pstree[treemode=R, nodesep=1pt]{\Tp*}{
	\pstree[linestyle=none]{\TR[edge=none]{$X$}}{\pstree{\TR{$Y$}}{\pstree{\TR{$E$}}{\TR{$P$}}}}
	\pstree{\TR{$A$}\taput{\scriptsize $P(A)$}}{
		\pstree[linestyle=none]{\TR{$C$}\taput{\scriptsize $P(C/A)$}}{\pstree{\TR{$(A,C)$}}{\TR{$P(A)P(C/A)$}}}
		\pstree[linestyle=none]{\TR{$D$}\taput{\scriptsize $P(D/A)$}}{\pstree{\TR{$(A,D)$}}{\TR{$P(A)P(D/A)$}}}
	}
	\pstree{\TR{$B$}\taput{\scriptsize $P(B)$}}{
		\pstree[linestyle=none]{\TR{$C$}\taput{\scriptsize $P(C/B)$}}{\pstree{\TR{$(B,C)$}}{\TR{$P(B)P(C/B)$}}}
		\pstree[linestyle=none]{\TR{$D$}\taput{\scriptsize $P(D/B)$}}{\pstree{\TR{$(B,D)$}}{\TR{$P(B)P(D/B)$}}}
	}
	\pstree[linestyle=none]{\Tp[edge=none]}{\Tp}
}
}
\end{center}

\note{
Ya se vio que en experimentos donde se medía más de una variable, era conveniente construir el espacio muestral
mediante un diagrama de árbol.

Dicho diagrama también es útil para calcular las probabilidades de cada uno de los elementos del espacio muestral del siguiente modo:
\begin{enumerate}
\item Para cada nodo del árbol, etiquetar su rama con la probabilidad de que la variable correspondiente tome el valor del nodo, condicionada por la ocurrencia de todos los nodos que conducen hasta el actual.
\item La probabilidad de cada suceso elemental se calcula multiplicando las probabilidades que etiquetan las ramas que
conducen hasta él.
\end{enumerate}
}
\end{frame}


% ---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Árboles de probabilidad con variables dependientes}
\framesubtitle{Ejemplo de dependencia del cáncer con respecto al tabaco}
Sea una población en la que el 30\% de las personas fuman, y que la incidencia del cáncer de pulmón en fumadores es del 40\% mientras que en
los no fumadores es del 10\%.

El espacio probabilístico de este experimento es:

\begin{center}
\psset{treesep=0.6cm, levelsep=2.5cm, tpos=0.6}
\renewcommand{\psedge}[2]{\ncdiag[armA=0.8cm,angleA=180,angleB=0,armB=0cm]{#2}{#1}} 
\pstree[treemode=R, nodesep=1pt]{\Tp*}{
	\pstree[linestyle=none]{\TR[edge=none]{Tabaco}}{
		\pstree{\TR{Enfermedad}}{
			\pstree{\TR{$E$}}{\TR{$P$}}
		}
	}
	\pstree{\TR{Fuma}\taput{\scriptsize $0.3$}}{
		\pstree[linestyle=none]{\TR{Cáncer}\taput{\scriptsize $0.4$}}{
			\pstree{\TR{(Fuma,Cáncer)}}{\TR{$0.3\cdot 0.4 = 0.12$}}
		}
		\pstree[linestyle=none]{\TR{$\overline{\mbox{Cáncer}}$}\taput{\scriptsize $0.6$}}{
			\pstree{\TR{(Fuma,$\overline{\mbox{Cáncer}}$)}}{\TR{$0.3\cdot 0.6 = 0.18$}}
		}
	}
	\pstree{\TR{$\overline{\mbox{Fuma}}$}\taput{\scriptsize $0.7$}}{
		\pstree[linestyle=none]{\TR{Cáncer}\taput{\scriptsize $0.1$}}{
			\pstree{\TR{($\overline{\mbox{Fuma}}$,Cáncer)}}{\TR{$0.7\cdot 0.1 = 0.07$}}
		}
		\pstree[linestyle=none]{\TR{$\overline{\mbox{Cáncer}}$}\taput{\scriptsize $0.9$}}{
			\pstree{\TR{($\overline{\mbox{Fuma}}$,$\overline{\mbox{Cáncer}}$)}}{\TR{$0.7\cdot 0.9 = 0.63$}}
		}
	}
	\pstree[linestyle=none]{\Tp[edge=none]}{\Tp}
}
\end{center}

\note{
Sea una población en la que el 30\% de las personas fuman, y que la incidencia del cáncer de pulmón en fumadores es del 40\% mientras que en
los no fumadores es del 10\%.

El árbol de probabilidad que expresa este experimento es el siguiente:

Obsérvese que el fumar o no depende del sexo, así que las ramas que salen del suceso mujer no tienen las mismas probabilidades que las que
salen del suceso hombre. }
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Árboles de probabilidad con variables independientes}
\framesubtitle{Ejemplo de independencia en el lanzamiento de dos monedas}

El árbol de probabilidad asociado al experimento aleatorio que consiste en el lanzamiento de dos monedas es:

\begin{center}
\psset{treesep=0.6cm, levelsep=2.5cm, tpos=0.7}
\renewcommand{\psedge}[2]{\ncdiag[armA=0.8cm,angleA=180,angleB=0,armB=0cm]{#2}{#1}} 
\pstree[treemode=R, nodesep=1pt]{\Tp*}{
	\pstree[linestyle=none]{\TR[edge=none]{1ª Moneda}}{\pstree{\TR{2ª Moneda}}{\pstree{\TR{$E$}}{\TR{$P$}}}}
	\pstree{\TR{C}\taput{\scriptsize $0.5$}}{
		\pstree[linestyle=none]{\TR{C}\taput{\scriptsize $0.5$}}{\pstree{\TR{(C,C)}}{\TR{$0.5\cdot 0.5 = 0.25$}}}
		\pstree[linestyle=none]{\TR{X}\taput{\scriptsize $0.5$}}{\pstree{\TR{(C,X)}}{\TR{$0.5\cdot 0.5 = 0.25$}}}
	}
	\pstree{\TR{X}\taput{\scriptsize $0.5$}}{
		\pstree[linestyle=none]{\TR{C}\taput{\scriptsize $0.5$}}{\pstree{\TR{(X,C)}}{\TR{$0.5\cdot 0.5 = 0.25$}}}
		\pstree[linestyle=none]{\TR{X}\taput{\scriptsize $0.5$}}{\pstree{\TR{(X,X)}}{\TR{$0.5\cdot 0.5 = 0.25$}}}
	}
	\pstree[linestyle=none]{\Tp[edge=none]}{\Tp}
}
\end{center}

\note{
El árbol de probabilidad asociado al experimento aleatorio que consiste en el lanzamiento de dos monedas es:

Obsérvese ahora que el resultado de la segunda moneda no depende del resultado de la primera, de manera que las ramas que salen del suceso
cara en la primera moneda tienen las mismas probabilidades que las que salen del suceso cruz.
}
\end{frame}




%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Árboles de probabilidad con variables independientes}
\framesubtitle{Ejemplo de independencia en la elección de una muestra aleatoria de tamaño 3}
Dada una población en la que hay un 40\% de hombres y un 60\% de mujeres, el experimento aleatorio que consiste en tomar una muestra
aleatoria de tres personas tiene el siguiente árbol de probabilidad:

\begin{center}
\psset{treesep=0.4cm, levelsep=2cm, tpos=0.7}
\renewcommand{\psedge}[2]{\ncdiag[armA=0.8cm,angleA=180,angleB=0,armB=0cm]{#2}{#1}} 
\pstree[treemode=R, nodesep=1pt]{\Tp*}{
	\pstree[linestyle=none]{\TR[edge=none]{1ª Persona}}{
		\pstree{\TR{2ª Persona}}{
			\pstree[thislevelsep=1cm]{\TR{3ª Persona}}{
				\pstree[thislevelsep=2.5cm]{\TR{$E$}}{\TR{$P$}}
			}
		}
	}
	\pstree{\TR{H}\taput{\scriptsize $0.4$}}{
		\pstree{\TR{H}\taput{\scriptsize $0.4$}}{
			\pstree[linestyle=none,thislevelsep=1.5cm]{\TR{H}\taput{\scriptsize $0.4$}}{
				\pstree[thislevelsep=2.5cm]{\TR{(H,H,H)}}{\TR{$0.4\cdot 0.4\cdot 0.4 = 0.064$}}
			}
			\pstree[linestyle=none,thislevelsep=1.5cm]{\TR{M}\taput{\scriptsize $0.6$}}{
				\pstree[thislevelsep=2.5cm]{\TR{(H,H,M)}}{\TR{$0.4\cdot 0.4\cdot 0.6 = 0.096$}}
			}
		}
		\pstree{\TR{M}\taput{\scriptsize $0.6$}}{
			\pstree[linestyle=none,thislevelsep=1.5cm]{\TR{H}\taput{\scriptsize $0.4$}}{
				\pstree[thislevelsep=2.5cm]{\TR{(H,M,H)}}{\TR{$0.4\cdot 0.6\cdot 0.4 = 0.096$}}
			}
			\pstree[linestyle=none,thislevelsep=1.5cm]{\TR{M}\taput{\scriptsize $0.6$}}{
				\pstree[thislevelsep=2.5cm]{\TR{(H,M,M)}}{\TR{$0.4\cdot 0.6\cdot 0.6 = 0.144$}}
			}
		}	
	}
	\pstree{\TR{M}\taput{\scriptsize $0.6$}}{
		\pstree{\TR{H}\taput{\scriptsize $0.4$}}{
			\pstree[linestyle=none,thislevelsep=1.5cm]{\TR{H}\taput{\scriptsize $0.4$}}{
				\pstree[thislevelsep=2.5cm]{\TR{(M,H,H)}}{\TR{$0.6\cdot 0.4\cdot 0.4 = 0.096$}}
			}
			\pstree[linestyle=none,thislevelsep=1.5cm]{\TR{M}\taput{\scriptsize $0.6$}}{
				\pstree[thislevelsep=2.5cm]{\TR{(M,H,M)}}{\TR{$0.6\cdot 0.4\cdot 0.6 = 0.144$}}
			}
		}
		\pstree{\TR{M}\taput{\scriptsize $0.6$}}{
			\pstree[linestyle=none,thislevelsep=1.5cm]{\TR{H}\taput{\scriptsize $0.4$}}{
				\pstree[thislevelsep=2.5cm]{\TR{(M,M,H)}}{\TR{$0.6\cdot 0.6\cdot 0.4 = 0.144$}}
			}
			\pstree[linestyle=none,thislevelsep=1.5cm]{\TR{M}\taput{\scriptsize $0.6$}}{
				\pstree[thislevelsep=2.5cm]{\TR{(M,M,M)}}{\TR{$0.6\cdot 0.6\cdot 0.6 = 0.216$}}
			}
		}	
	}
	\pstree[linestyle=none]{\Tp[edge=none]}{\Tp}
}
\end{center}

\note{
Otro ejemplo de árbol con independencia sería la obtención de una muestra aleatoria con reemplazamiento. 
Dada una población en la que hay un 40\% de hombres y un 60\% de mujeres, el experimento aleatorio que consiste en tomar una muestra
aleatoria con reemplazamiento de tres personas tiene el siguiente árbol de probabilidad:

Obsérvese de nuevo cómo todas las ramas del suceso hombre tienen las mismas probabilidades y lo mismo ocurre con las ramas del suceso mujer. 
}
\end{frame}


\subsection{Teorema de la probabilidad total}

%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Sistema completo de sucesos}
\begin{definicion}[Sistema completo de sucesos]
Una colección de sucesos $A_1,A_2,\ldots,A_n$ de un mismo espacio de sucesos es un \emph{sistema completo} si cumple las siguientes condiciones:
\begin{enumerate}
\item La unión de todos es el espacio muestral: $A_1\cup \cdots\cup A_n =E$.
\item Son incompatibles dos a dos: $A_i\cap A_j = \emptyset$ $\forall i\neq j$.
\end{enumerate}
\end{definicion}
\begin{center}
\psset{unit=0.8}
\begin{pspicture}(0,0)(5,3.5)
\psset{fillstyle=solid}
\pscustom[fillcolor=white]{\psframe(0,0)(5,3)}
\psline(1,0)(1,3)
\psline(2,0)(2,3)
\psline(4,0)(4,3)
\rput(0.5,1.5){$A_1$}
\rput(1.5,1.5){$A_2$}
\rput(3,1.5){$\cdots$}
\rput(4.5,1.5){$A_n$}
\rput[b](0.2,3.2){$E$}
\end{pspicture}
\end{center}

En realidad un sistema completo de sucesos es una partición del espacio muestral de acuerdo a algún atributo, como por ejemplo el sexo o el
grupo sanguíneo.

\note{
En algunos experimentos es posible descomponer el espacio muestral en partes que forman un sistema completo de sucesos. 

\begin{definicion}[Sistema completo de sucesos]
Una colección de sucesos $A_1,A_2,\ldots,A_n$ de un mismo espacio de sucesos es un \emph{sistema completo} si cumple las siguientes condiciones:
\begin{enumerate}
\item La unión de todos es el espacio muestral: $A_1\cup \cdots\cup A_n =E$.
\item Son incompatibles dos a dos: $A_i\cap A_j = \emptyset$ $\forall i\neq j$.
\end{enumerate}
\end{definicion}

En realidad un sistema completo de sucesos es una partición del espacio muestral de acuerdo a algún atributo, como por ejemplo el sexo o el
grupo sanguíneo.
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Teorema de la probabilidad total}
Conocer las probabilidades de un determinado suceso en cada una de las partes de un sistema completo puede ser útil para calcular su
probabilidad.
\begin{teorema}[Probabilidad total]
Dado un sistema completo de sucesos $A_1,\ldots,A_n$ y un suceso $B$ de un mismo espacio de sucesos, se cumple
\[
P(B) = \sum_{i=1}^n P(A_i)P(B/A_i).
\]
\end{teorema}

\begin{center}
\psset{unit=1}
\begin{pspicture}(0,0)(5,3.5)
\psset{fillstyle=solid}
\pscustom[fillcolor=white]{\psframe(0,0)(5,3)}
\pscustom[fillcolor=coral]{\psellipse(2.5,1.5)(2,1)}
\psline(1,0)(1,3)
\psline(2,0)(2,3)
\psline(4,0)(4,3)
\rput(0.5,0.2){$A_1$}
\rput(1.5,0.2){$A_2$}
\rput(3,0.2){$\cdots$}
\rput(4.5,0.2){$A_n$}
\rput(3,1.5){$B$}
\rput[b](0.2,3.2){$E$}
\end{pspicture}
\end{center}

\note{
Conocer las probabilidades de un determinado suceso en cada una de las partes de un sistema completo puede ser útil para calcular su
probabilidad.
\begin{teorema}[Probabilidad total]
Dado un sistema completo de sucesos $A_1,\ldots,A_n$ y un suceso $B$ de un mismo espacio de sucesos, se cumple
\[
P(B) = \sum_{i=1}^n P(A_i)P(B/A_i).
\]
\end{teorema}
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Teorema de la probabilidad total}
\framesubtitle{Demostración}
La demostración del teorema es sencilla, ya que al ser $A_1,\ldots,A_n$ un sistema completo tenemos
\[
B = B\cap E = B\cap (A_1\cup \cdots \cup A_n) = (B\cap A_1)\cup \cdots \cup (B\cap A_n)
\]
y como estos sucesos son incompatibles entre sí, se tiene
\begin{align*}
P(B) &= P((B\cap A_1)\cup \cdots \cup (B\cap A_n)) = P(B\cap A_1)+\cdots + P(B\cap A_n) =\\
&= P(A_1)P(B/A_1)+\cdots + P(A_n)P(B/A_n) = \sum_{i=1}^n P(A_i)P(B/A_i).
\end{align*}

\note{
La demostración del teorema es sencilla, ya que al ser $A_1,\ldots,A_n$ un sistema completo tenemos
\[
B = B\cap E = B\cap (A_1\cup \cdots \cup A_n) = (B\cap A_1)\cup \cdots \cup (B\cap A_n)
\]
y como estos sucesos son incompatibles entre sí, se tiene
\begin{align*}
P(B) &= P((B\cap A_1)\cup \cdots \cup (B\cap A_n)) = P(B\cap A_1)+\cdots + P(B\cap A_n) =\\
&= P(A_1)P(B/A_1)+\cdots + P(A_n)P(B/A_n) = \sum_{i=1}^n P(A_i)P(B/A_i).
\end{align*}
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Teorema de la probabilidad total}
\framesubtitle{Un ejemplo de diagnóstico}
Un determinado síntoma $B$ puede ser originado por una enfermedad $A$ pero también lo pueden presentar las personas sin
la enfermedad. Sabemos que en la población la tasa de personas con la enfermedad A es $0.2$. Además, de las personas
que presentan la enfermedad, el $90\%$ presentan el síntoma, mientras que de las personas sin la enfermedad sólo lo presentan el $40\%$.

Si se toma una persona al azar de la población, \emph{¿qué probabilidad hay de que tenga el síntoma?}

Para responder a la pregunta hay que fijarse en que el conjunto de sucesos $\{A,\overline{A}\}$ es un sistema completo, ya que $A\cup \overline A = E$ y $A\cap \overline A = \emptyset$, de modo que se puede aplicar el teorema de la probabilidad total:
\[
P(B) = P(A)P(B/A)+P(\overline A)P(B/\overline A) = 0.2\cdot 0.9 + 0.8\cdot 0.4 = 0.5.
\]
Es decir, la mitad de la población tendrá el síntoma. 

\begin{center}
\emph{¡En el fondo se trata de una media ponderada de probabilidades!} 
\end{center}

\note{
Veamos un ejemplo de aplicación del teorema de la probabilidad total.

Supongamos que un determinado síntoma $B$ puede ser originado por una enfermedad $A$ pero también lo pueden presentar las personas sin
la enfermedad. Sabemos que en la población la tasa de personas con la enfermedad A es $0.2$. Además, de las personas
que presentan la enfermedad, el $90\%$ presentan el síntoma, mientras que de las personas sin la enfermedad sólo lo presentan el $40\%$.

Si se toma una persona al azar de la población, \emph{¿qué probabilidad hay de que tenga el síntoma?}

Para responder a la pregunta hay que fijarse en que el conjunto de sucesos $\{A,\overline{A}\}$ es un sistema completo, ya que $A\cup \overline A = E$ y $A\cap \overline A = \emptyset$, de modo que se puede aplicar el teorema de la probabilidad total:
\[
P(B) = P(A)P(B/A)+P(\overline A)P(B/\overline A) = 0.2\cdot 0.9 + 0.8\cdot 0.4 = 0.5.
\]
Es decir, la mitad de la población tendrá el síntoma. 

\begin{center}
\emph{¡En el fondo se trata de una media ponderada de probabilidades!} 
\end{center}
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Teorema de la probabilidad total}
\framesubtitle{Cálculo con el árbol de probabilidad}
La respuesta a la pregunta anterior es evidente a la luz del espacio probabilístico del experimento. 
\begin{center}
\psset{treesep=0.6cm, levelsep=2.5cm, tpos=0.6}
\renewcommand{\psedge}[2]{\ncdiag[armA=0.8cm,angleA=180,angleB=0,armB=0cm]{#2}{#1}} 
\pstree[treemode=R, nodesep=1pt]{\Tp*}{
	\pstree[linestyle=none]{\TR[edge=none]{Enfermedad}}{
		\pstree{\TR{Síntoma}}{
			\pstree{\TR{$E$}}{\TR{$P$}}
		}
	}
	\pstree{\TR{$A$}\taput{\scriptsize $0.2$}}{
		\pstree[linestyle=none]{\TR{$B$}\taput{\scriptsize $0.9$}}{
			\pstree{\TR{\alert{$(A,B)$}}}{\TR{\alert{$0.2\cdot 0.9 = 0.18$}}}
		}
		\pstree[linestyle=none]{\TR{$\overline B$}\taput{\scriptsize $0.1$}}{
			\pstree{\TR{$(A,\overline B)$}}{\TR{$0.2\cdot 0.1 = 0.02$}}
		}
	}
	\pstree{\TR{$\overline A$}\taput{\scriptsize $0.8$}}{
		\pstree[linestyle=none]{\TR{$B$}\taput{\scriptsize $0.4$}}{
			\pstree{\TR{\alert{$(\overline A,B)$}}}{\TR{\alert{$0.8\cdot 0.4 = 0.32$}}}
		}
		\pstree[linestyle=none]{\TR{$\overline B$}\taput{\scriptsize $0.6$}}{
			\pstree{\TR{$(\overline A,\overline B)$}}{\TR{$0.8\cdot 0.6 = 0.48$}}
		}
	}
	\pstree[linestyle=none]{\Tp[edge=none]}{\Tp}
}
\end{center}
\begin{align*}
P(B) &= P(A,B) + P(\overline A,B) =\\
&= P(A)P(B/A)+P(\overline A)P(B/\overline A) = 0.2\cdot 0.9+ 0.8\cdot 0.4 = 0.18 + 0.32 = 0.5. 
\end{align*}

\note{
El teorema de la probabilidad total también puede deducirse fácilmente a partir del diagrama de árbol de este experimento. 
}
\end{frame}


\subsection{Teorema de Bayes}

%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Teorema de Bayes}
Los sucesos de un sistema completo de sucesos $A_1,\cdots,A_n$ también pueden verse como las distintas hipótesis ante
un determinado hecho $B$.

En estas condiciones resulta útil poder calcular las probabilidades a posteriori $P(A_i/B)$ de cada una de las hipótesis.

\begin{teorema}[Bayes]
Dado un sistema completo de sucesos $A_1,\ldots,A_n$ y un suceso $B$ de un mismo espacio de sucesos, se cumple
\[
P(A_i/B) = \frac{P(A_i\cap B)}{P(B)} = \frac{P(A_i)P(B/A_i)}{\sum_{i=1}^n P(A_i)P(B/A_i)}.
\]
\end{teorema}

\note{
Los sucesos de un sistema completo de sucesos $A_1,\cdots,A_n$ también pueden verse como las distintas hipótesis ante
un determinado hecho $B$.

En estas condiciones puede ser útil calcular las probabilidades a posteriori $P(A_i/B)$ de cada una de las hipótesis, es decir, una vez
se haya cumplido el suceso $B$. Para ello se utiliza el teorema de Bayes. 

\begin{teorema}[Bayes]
Dado un sistema completo de sucesos $A_1,\ldots,A_n$ y un suceso $B$ de un mismo espacio de sucesos, se cumple
\[
P(A_i/B) = \frac{P(A_i\cap B)}{P(B)} = \frac{P(A_i)P(B/A_i)}{\sum_{i=1}^n P(A_i)P(B/A_i)}.
\]
\end{teorema}
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Teorema de Bayes}
\framesubtitle{Un ejemplo de diagnóstico}
En el ejemplo anterior se ha visto cómo calcular la probabilidad de que una persona elegida al azar presente el síntoma, pero desde un punto
de vista de diagnóstico clínico, una pregunta más interesante es:
  
Si llega a la consulta una persona que presenta el síntoma, \emph{¿qué se debe diagnosticar?}

En este caso, las hipótesis ante las que hay que decidir son $A$ y $\overline A$ y sus probabilidades ``a priori'' son $P(A)=0.2$ y
$P(\overline A)=0.8$.

Esto quiere decir que si no hubiese ninguna información sobre la persona, el diagnóstico sería que no tiene la enfermedad pues es mucho más
probable que que la tenga.

Sin embargo, si al reconocer a la persona se observa que presenta el síntoma, dicha información condiciona a las hipótesis, y para decidir
entre ellas es necesario calcular sus probabilidades ``a posteriori'', es decir 
\[ P(A/B) \mbox{ y } P(\overline A/B)\]

\note{
En el ejemplo anterior se ha visto cómo calcular la probabilidad de que una persona elegida al azar presente el síntoma, pero desde un punto
de vista de diagnóstico clínico, una pregunta más interesante es:
  
Si llega a la consulta una persona que presenta el síntoma, \emph{¿qué se debe diagnosticar?}

En este caso, las hipótesis ante las que hay que decidir son $A$ y $\overline A$ y sus probabilidades ``a priori'' son $P(A)=0.2$ y
$P(\overline A)=0.8$.

Esto quiere decir que si no hubiese ninguna información sobre la persona, el diagnóstico sería que no tiene la enfermedad pues es mucho más
probable que que la tenga.

Sin embargo, si al reconocer a la persona se observa que presenta el síntoma, dicha información condiciona a las hipótesis, y para decidir
entre ellas es necesario calcular sus probabilidades ``a posteriori'', es decir 
\[ P(A/B) \mbox{ y } P(\overline A/B)\]
}
\end{frame}


%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Teorema de Bayes}
\framesubtitle{Un ejemplo de diagnóstico}
Para calcular las probabilidades ``a posteriori'' se puede utilizar el teorema de Bayes:
\begin{align*}
P(A/B) &= \frac{P(A)P(B/A)}{P(A)P(B/A)+P(\overline A)P(B/\overline A)} = \frac{0.2\cdot 0.9}{0.2\cdot 0.9 + 0.8\cdot 0.4} = \frac{0.18}{0.5}=0.36,\\
P(\overline A/B) &= \frac{P(\overline A)P(B/\overline A)}{P(A)P(B/A)+P(\overline A)P(B/\overline A)} = \frac{0.8\cdot 0.4}{0.2\cdot 0.9 + 0.8\cdot 0.4} = \frac{0.32}{0.5}=0.64.
\end{align*}
Según esto, a pesar de que la probabilidad de estar enfermo ha aumentado, seguiríamos diagnosticando que no lo está, puesto que es más
probable.

En este caso se dice que el síntoma $B$ \emph{no es determinante} a la hora de diagnosticar la enfermedad, pues la información que aporta no
sirve para cambiar el diagnóstico en ningún caso.

\note{
Para calcular las probabilidades ``a posteriori'' se puede utilizar el teorema de Bayes:
\begin{align*}
P(A/B) &= \frac{P(A)P(B/A)}{P(A)P(B/A)+P(\overline A)P(B/\overline A)} = \frac{0.2\cdot 0.9}{0.2\cdot 0.9 + 0.8\cdot 0.4} = \frac{0.18}{0.5}=0.36,\\
P(\overline A/B) &= \frac{P(\overline A)P(B/\overline A)}{P(A)P(B/A)+P(\overline A)P(B/\overline A)} = \frac{0.8\cdot 0.4}{0.2\cdot 0.9 + 0.8\cdot 0.4} = \frac{0.32}{0.5}=0.64.
\end{align*}
Según esto, a pesar de que la probabilidad de estar enfermo ha aumentado, seguiríamos diagnosticando que no lo está, puesto que es más
probable.

En este caso se dice que el síntoma $B$ \emph{no es determinante} a la hora de diagnosticar la enfermedad, pues la información que aporta no
sirve para cambiar el diagnóstico en ningún caso.
}
\end{frame}

\subsection{Tests diagnósticos}

%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Tests diagnósticos}
En epidemiología es común el uso de tests para diagnosticar enfermedades.

Generalmente estos tests no son totalmente fiables, sino que hay cierta probabilidad de acierto o fallo en el diagnóstico, que suele
representarse en la siguiente tabla:
\begin{center}
\begin{tabular}{|m{3cm}<{\centering}|m{3.5cm}<{\centering}|m{3.5cm}<{\centering}|}
\cline{2-3}
\multicolumn{1}{c|}{} & Presencia de la\newline enfermedad ($E$) & Ausencia de la\newline enfermedad ($\overline E$)\\ \hline
Test positivo\newline ($+$) & \textcolor{green}{Diagnóstico acertado\newline  $P(+/E)$}\qquad
\structure{Sensibilidad}& \textcolor{red}{Diagnóstico erróneo\newline $P(+/\overline E)$}\\ \hline Test negativo\newline ($-$) &
\textcolor{red}{Diagnóstico erróneo\newline $P(-/E)$} & \textcolor{green}{Diagnóstico acertado\newline $P(-/\overline
E)$}\qquad \structure{Especificidad}\\ \hline
\end{tabular}
\end{center}

\note{
En epidemiología es común el uso de tests para diagnosticar enfermedades.

Generalmente estos tests no son totalmente fiables, sino que hay cierta probabilidad de acierto o fallo en el diagnóstico, que suele
representarse en la siguiente tabla:
\begin{center}
\begin{tabular}{|m{3cm}<{\centering}|m{3.5cm}<{\centering}|m{3.5cm}<{\centering}|}
\cline{2-3}
\multicolumn{1}{c|}{} & Presencia de la\newline enfermedad ($E$) & Ausencia de la\newline enfermedad ($\overline E$)\\ \hline
Test positivo\newline ($+$) & \textcolor{green}{Diagnóstico acertado\newline  $P(+/E)$}\newline\structure{Sensibilidad}& \textcolor{red}{\noindent Diagnóstico erróneo\newline $P(+/\overline E)$}\\ \hline
Test negativo\newline ($-$) & \textcolor{red}{Diagnóstico erróneo\newline $P(-/E)$} & \textcolor{green}{Diagnóstico acertado\newline $P(-/\overline E)$}\newline\structure{Especificidad}\\ \hline
\end{tabular}
\end{center}
}
\end{frame}



%---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Tests diagnósticos}
La valided de una prueba diagnóstica depende de estas dos probabilidades:
\begin{description}
\item[\textbf{Sensibilidad}] Es el porcentaje de positivos entre las personas enfermas: $P(+/E)$.
\item[\textbf{Especificidad}] Es el porcentaje de negativos entre las personas sanas: $P(-/\bar E)$.
\end{description}

Pero lo realmente interesante de un un test diagnóstico es su capacidad predictiva para diagnosticar, lo cual se mide mediante las
siguientes probabilidades a posteriori:
\begin{description}
\item[\textbf{Valor predictivo positivo}] Es el porcentaje de enfermos entre los positivos: $P(E/+)$.
\item[\textbf{Valor predictivo negativo}] Es el porcentaje de sanos entre los negativos: $P(\bar E/-)$.
\end{description}

Sin embargo, estos últmos valores dependen del porcentaje de enfermos en la población $P(E)$, lo que se conoce como, \structure{\textbf{tasa
o prevalencia}} de la enfermedad.

\note{
La valided de una prueba diagnóstica depende de estas dos probabilidades:
\begin{description}
\item[Sensibilidad] Es el porcentaje de positivos entre las personas enfermas: $P(+/E)$.
\item[Especificidad] Es el porcentaje de negativos entre las personas sanas: $P(-/\bar E)$.
\end{description}

Pero lo realmente interesante de un un test diagnóstico es su capacidad predictiva para diagnosticar, lo cual se mide mediante las
siguientes probabilidades a posteriori:
\begin{description}
\item[Valor predictivo positivo] Es el porcentaje de enfermos entre los positivos: $P(E/+)$.
\item[Valor predictivo negativo] Es el porcentaje de sanos entre los negativos: $P(\bar E/-)$.
\end{description}

Sin embargo, estos últimos valores dependen del porcentaje de enfermos en la población $P(E)$, lo que se conoce como,
\structure{\textbf{tasa o prevalencia}} de la enfermedad.
}
\end{frame}


% ---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Tests diagnósticos}
\frametitle{Ejemplo}
Un test para diagnosticar la gripe tiene una sensibilidad del $95\%$ y una especificidad del $90\%$. Según esto, las probabilidades de
acierto y fallo del test son:
\begin{center}
\begin{tabular}{|c|c|c|}
\cline{2-3}
\multicolumn{1}{c|}{} & Gripe & No gripe\\ \hline
Test $+$ & \textcolor{green}{$0.95$} & \textcolor{red}{$0.10$}\\ \hline
Test $-$ & \textcolor{red}{$0.05$} & \textcolor{green}{$0.90$}\\ \hline
\end{tabular}
\end{center}

Si la prevalencia de la gripe en la población es del $10\%$ y al aplicar el test a un individuo da positivo, \emph{¿cuál es la probabilidad
de que tenga gripe?}

Aplicando el teorema de Bayes, se tiene que el valor predictivo positivo del test vale
\begin{align*}
P(\mbox{Gripe}/+) &= \frac{P(\mbox{Gripe})P(+/\mbox{Gripe})}{P(\mbox{Gripe})P(+/\mbox{Gripe})+P(\overline{\mbox{Gripe}})P(+/\overline{\mbox{Gripe}})} =\\
&= \frac{0.1\cdot 0.95}{0.1\cdot 0.95+0.9\cdot 0.1} = 0.5135.
\end{align*}
Aunque con esta probabilidad se diagnosticaría la enfermedad en caso de que el test diese positivo, se trata de un valor predictivo positivo
muy bajo. 

\note{
Veamos un ejemplo. 

Un test para diagnosticar la gripe tiene una sensibilidad del $95\%$ y una especificidad del $90\%$. Según esto, las probabilidades de
acierto y fallo del test son:
\begin{center}
\begin{tabular}{|c|c|c|}
\cline{2-3}
\multicolumn{1}{c|}{} & Gripe & No gripe\\ \hline
Test $+$ & \textcolor{green}{$0.95$} & \textcolor{red}{$0.10$}\\ \hline
Test $-$ & \textcolor{red}{$0.05$} & \textcolor{green}{$0.90$}\\ \hline
\end{tabular}
\end{center}

Si la prevalencia de la gripe en la población es del $10\%$ y al aplicar el test a un individuo da positivo, \emph{¿cuál es la probabilidad
de que tenga gripe?}

Aplicando el teorema de Bayes, se tiene
\begin{align*}
P(\mbox{Gripe}/+) &= \frac{P(\mbox{Gripe})P(+/\mbox{Gripe})}{P(\mbox{Gripe})P(+/\mbox{Gripe})+P(\overline{\mbox{Gripe}})P(+/\overline{\mbox{Gripe}})} =\\
&= \frac{0.1\cdot 0.95}{0.1\cdot 0.95+0.9\cdot 0.1} = 0.51.
\end{align*}

La probabilidad de no tener la gripe sería $1-0.51=0.49$ ya que es el suceso contrario de tener la gripe, y como la probabilidad de tener la
gripe es mayor que la de no tenerla, se diagnosticaría que tiene gripe. Sin embargo, el valor predictivo positivo de este test es muy bajo y
nos equivoaríamos en el 49\% de los diagnósticos de enfermedad.
}
\end{frame}


% ---------------------------------------------------------------------slide----
\begin{frame}
\frametitle{Tests diagnósticos}
\frametitle{Ejemplo}
\begin{center}
\begin{tabular}{|c|c|c|}
\cline{2-3}
\multicolumn{1}{c|}{} & Gripe & No gripe\\ \hline
Test $+$ & \textcolor{green}{$0.95$} & \textcolor{red}{$0.10$}\\ \hline
Test $-$ & \textcolor{red}{$0.05$} & \textcolor{green}{$0.90$}\\ \hline
\end{tabular}
\end{center}

Y si el test da negativo, \emph{¿cuál es la probabilidad de que no tenga gripe?}

De nuevo, aplicando el teorema de Bayes, se tiene que el valor predictivo negativo del test vale
\begin{align*}
P(\overline{\mbox{Gripe}}/-) &=
\frac{P(\overline{\mbox{Gripe}})P(-/\overline{\mbox{Gripe}})}{P(\mbox{Gripe})P(-/\mbox{Gripe})+P(\overline{\mbox{Gripe}})P(-/\overline{\mbox{Gripe}})}
=\\ &= \frac{0.9\cdot 0.9}{0.1\cdot 0.05+0.9\cdot 0.9} = 0.9939.
\end{align*}
De manera que el valor predictivo negativo de este test es mucho más alto que el valor predictivo positivo.

\note{
Y si el test da negativo, \emph{¿cuál es la probabilidad de que no tenga gripe?}

De nuevo, aplicando el teorema de Bayes, se tiene que el valor predictivo negativo del test vale
\begin{align*}
P(\overline{\mbox{Gripe}}/-) &=
\frac{P(\overline{\mbox{Gripe}})P(-/\overline{\mbox{Gripe}})}{P(\mbox{Gripe})P(-/\mbox{Gripe})+P(\overline{\mbox{Gripe}})P(-/\overline{\mbox{Gripe}})}
=\\ &= \frac{0.9\cdot 0.9}{0.1\cdot 0.05+0.9\cdot 0.9} = 0.9939.
\end{align*}
De manera que el valor predictivo negativo de este test es mucho más alto que el valor predictivo positivo, y por tanto este test es mucho
más útil para descartar la enfermedad que para detectarla. 
}
\end{frame}

